{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow\n",
    "\n",
    "The aeon custom model flavor enables logging of aeon models in MLflow format via the `aeon.utils.mlflow_aeon.save_model()` and `aeon.utils.mlflow_aeon.log_model()` methods. These methods also add the `pyfunc` flavor to the MLflow Models that they produce, allowing the model to be interpreted as generic Python functions for inference via `aeon.utils.mlflow_aeon.pyfunc.load_model()`. This loaded PyFunc model can only be scored with a DataFrame input. You can also use the `aeon.utils.mlflow_aeon.load_model()` method to load MLflow Models with the aeon model flavor in native aeon formats.\n",
    "\n",
    "The `pyfunc` flavor of the model supports aeon predict methods `predict`,  `predict_interval`, `predict_proba`, `predict_quantiles`, `predict_var`.\n",
    "\n",
    "The interface for utilizing a aeon model loaded as a `pyfunc` type for generating forecasts requires passing an exogenous regressor as Pandas DataFrame to the `pyfunc.predict()` method (an empty DataFrame must be passed if no exogenous regressor is used). The configuration of predict methods and parameter values passed to the predict methods is defined by a dictionary to be saved as an attribute of the fitted aeon model instance. If no prediction configuration is defined `pyfunc.predict()` will return output from aeon `predict` method. Note that for `pyfunc` flavor the forecasting horizon `fh` must be passed to the fit method.\n",
    "\n",
    "Predict methods and parameter values for `pyfunc` flavor can be defined in two ways:\n",
    "- `Dict[str, dict]` if parameter values are passed to `pyfunc.predict()`, for example  `{\"predict_method\": {\"predict\": {}, \"predict_interval\": {\"coverage\": [0.1, 0.9]}}`\n",
    "- `Dict[str, list]`, with default parameters in predict method, for example  `{\"predict_method\": [\"predict\", \"predict_interval\"}` (Note: when including `predict_proba` method the former appraoch must be followed as `quantiles` parameter has to be provided by the user)\n",
    "- If no prediction config is defined `pyfunc.predict()` will return output from aeon `predict()` method\n",
    "\n",
    "Signature logging for aeon from a non-pyfunc artifact will not function correctly for `predict_interval` or `predict_quantiles`. The output of the native aeon model flavor for these methods is not a recognized signature type due to the MultiIndex column structure of the returned DataFrame. MLflow's ``infer_schema`` will function correctly if using the ``pyfunc`` flavor of the model, though."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from aeon.datasets import load_longley\n",
    "from aeon.forecasting.model_selection import temporal_train_test_split\n",
    "from aeon.forecasting.naive import NaiveForecaster\n",
    "from aeon.utils import mlflow_aeon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "y, X = load_longley()\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = [0.8, 0.9]\n",
    "quantiles = [0.1, 0.9]\n",
    "\n",
    "pyfunc_predict_conf = {\n",
    "    \"predict_method\": {\n",
    "        \"predict\": {},\n",
    "        \"predict_interval\": {\"coverage\": coverage},\n",
    "        \"predict_proba\": {\"quantiles\": quantiles},\n",
    "        \"predict_quantiles\": {},\n",
    "        \"predict_var\": {},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    forecaster = NaiveForecaster()\n",
    "    forecaster.fit(\n",
    "        y_train,\n",
    "        X=X_train,\n",
    "        fh=[1, 2, 3],\n",
    "    )\n",
    "    forecaster.pyfunc_predict_conf = pyfunc_predict_conf\n",
    "\n",
    "    mlflow_aeon.save_model(forecaster, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load model\n",
    "\n",
    "#### 2.3.1 Native aeon flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow_aeon.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Pyfunc flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pyfunc = mlflow_aeon.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Generate predictions\n",
    "\n",
    "#### 2.4.1 Native aeon flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1959    66513.0\n1960    66513.0\n1961    66513.0\nFreq: A-DEC, dtype: float64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_interval(X=X_test, coverage=coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          Coverage                                          \n               0.8                         0.9              \n             lower         upper         lower         upper\n1959  64719.913711  68306.086289  64211.598663  68814.401337\n1960  63977.193051  69048.806949  63258.327017  69767.672983\n1961  63407.283445  69618.716555  62526.855956  70499.144044",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Coverage</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">0.8</th>\n      <th colspan=\"2\" halign=\"left\">0.9</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>lower</th>\n      <th>upper</th>\n      <th>lower</th>\n      <th>upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1959</th>\n      <td>64719.913711</td>\n      <td>68306.086289</td>\n      <td>64211.598663</td>\n      <td>68814.401337</td>\n    </tr>\n    <tr>\n      <th>1960</th>\n      <td>63977.193051</td>\n      <td>69048.806949</td>\n      <td>63258.327017</td>\n      <td>69767.672983</td>\n    </tr>\n    <tr>\n      <th>1961</th>\n      <td>63407.283445</td>\n      <td>69618.716555</td>\n      <td>62526.855956</td>\n      <td>70499.144044</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dist = loaded_model.predict_proba(X=X)\n",
    "y_pred_dist_quantiles = pd.DataFrame(y_pred_dist.quantile(quantiles))\n",
    "y_pred_dist_quantiles.columns = [f\"Quantiles_{q}\" for q in quantiles]\n",
    "y_pred_dist_quantiles.index = y_pred_dist.parameters[\"loc\"].index\n",
    "y_pred_dist_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "tensorflow-probability must be installed for fully probabilistic forecastsinstall `aeon` deep learning dependencies by `pip install aeon[dl]`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32mC:\\code\\aeon\\aeon\\utils\\validation\\_dependencies.py:219\u001B[0m, in \u001B[0;36m_check_dl_dependencies\u001B[1;34m(msg, severity)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 219\u001B[0m     \u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtensorflow\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m     import_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow_probability\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:984\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m y_pred_dist \u001B[38;5;241m=\u001B[39m \u001B[43mloaded_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m y_pred_dist_quantiles \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(y_pred_dist\u001B[38;5;241m.\u001B[39mquantile(quantiles))\n\u001B[0;32m      3\u001B[0m y_pred_dist_quantiles\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuantiles_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mq\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m quantiles]\n",
      "File \u001B[1;32mC:\\code\\aeon\\aeon\\forecasting\\base\\_base.py:772\u001B[0m, in \u001B[0;36mBaseForecaster.predict_proba\u001B[1;34m(self, fh, X, marginal)\u001B[0m\n\u001B[0;32m    764\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    765\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautomated vectorization for predict_proba is not implemented\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    766\u001B[0m     )\n\u001B[0;32m    768\u001B[0m msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    769\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow-probability must be installed for fully probabilistic forecasts\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    770\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minstall `aeon` deep learning dependencies by `pip install aeon[dl]`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    771\u001B[0m )\n\u001B[1;32m--> 772\u001B[0m \u001B[43m_check_dl_dependencies\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    774\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_is_fitted()\n\u001B[0;32m    775\u001B[0m \u001B[38;5;66;03m# input checks\u001B[39;00m\n",
      "File \u001B[1;32mC:\\code\\aeon\\aeon\\utils\\validation\\_dependencies.py:224\u001B[0m, in \u001B[0;36m_check_dl_dependencies\u001B[1;34m(msg, severity)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    223\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m severity \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 224\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m severity \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarning\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    226\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(msg)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: tensorflow-probability must be installed for fully probabilistic forecastsinstall `aeon` deep learning dependencies by `pip install aeon[dl]`"
     ]
    }
   ],
   "source": [
    "loaded_model.predict_quantiles(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict_var(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Pyfunc flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pyfunc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model deployment example\n",
    "\n",
    "### 3.1 Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_path = \"model\"\n",
    "\n",
    "mlflow.set_experiment(\"Test aeon\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    forecaster = NaiveForecaster()\n",
    "    forecaster.fit(y_train, X=X_train, fh=[1, 2, 3])\n",
    "    forecaster.pyfunc_predict_conf = pyfunc_predict_conf\n",
    "\n",
    "    mlflow_aeon.log_model(estimator=forecaster, artifact_path=artifact_path)\n",
    "\n",
    "run_id = run.info.run_id\n",
    "print(f\"MLflow run id: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deploy pyfunc model to local REST API endpoint\n",
    "- Open a terminal window and cd into `examples`directory\n",
    "- In the terminal run: `mlflow models serve -m runs:/<RUN_ID>/model --env-manager local --host <HOST>`\n",
    "    - where you substitute `<RUN_ID>` by the `run_id` and `<HOST>` by the network address to listen on (e.g. `127.0.0.1`)\n",
    "- More details here: https://www.mlflow.org/docs/latest/cli.html#mlflow-models-serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Request predictions from local REST API endpoint\n",
    "\n",
    "- For mor details see: https://www.mlflow.org/docs/latest/models.html#built-in-deployment-tools\n",
    "\n",
    "#### 3.3.1 JSON input using `dataframe_split` field with pandas DataFrame in the `split` orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"127.0.0.1\"\n",
    "url = f\"http://{host}:5000/invocations\"\n",
    "\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "json_data = {\"dataframe_split\": X_test.to_dict(orient=\"split\")}\n",
    "print(json_data)\n",
    "\n",
    "# # Comment in the below lines to run the prediction request\n",
    "# import requests\n",
    "# response = requests.post(url, json=json_data)\n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 JSON input using `dataframe_records` field with pandas DataFrame in the `records` orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\"dataframe_records\": X_test.to_dict(orient=\"records\")}\n",
    "print(json_data)\n",
    "\n",
    "# # Comment in the below lines to run the prediction request\n",
    "# response = requests.post(url, json=json_data)\n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 CSV input using valid `pd.DataFrame` csv representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"text/csv\",\n",
    "}\n",
    "data = X_test.to_csv()\n",
    "print(data)\n",
    "\n",
    "# # Comment in the below lines to run the prediction request\n",
    "# response = requests.post(url, headers=headers, data=data)\n",
    "# response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}