{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Time series clustering\n",
    "\n",
    "Time series clustering (TSCL) is a hugely popular research field that has engendered\n",
    "thousands of publications. The core problem is to group together\n",
    "Broadly, TSCL can be grouped into those that work with (possibly transformed) whole\n",
    "time series, and those that derive features that are not time dependent, and then use\n",
    " a standard clustering algorithm.\n",
    "\n",
    "This graph summarises the different approaches\n",
    "\n",
    "<img src=\"img/taxonomy.png\" width=\"1000\" alt=\"time series clustering\">\n",
    "\n",
    "Fig. 1. A taxonomy of time series clustering algorithms, taken from [1]. The\n",
    "following models are included:\n",
    "K-means [2], K-spectral centroid [3], K-DBA [4], Kernel K-means [5], K-\n",
    "shapes [6], K-multishapes [7], PAM [8], CLARA [9], CLARANS [10], Al-\n",
    "ternate [11], DBSCAN [12], HDBSCAN[13], OPTICS [14], BIRCH [15], Agglom-\n",
    "erative [16], Feature K-means [17], Feature K-medoids [17], U-shapelets [18],\n",
    "USSL [19], RSFS [20], NDFS [21], Deep learning and dimensionality reduction\n",
    "approaches see [22]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering notebooks\n",
    "\n",
    "- `aeon` currently focusses on partition based approaches that use elastic distance\n",
    "functions. The [partition based](partitional_clustering.ipynb) note book has an\n",
    "overview of the funtionality in aeon.\n",
    "\n",
    "- `sklearn` has *density based* and *hierarchical based* clustering algorithms, and\n",
    "these can be used in conjunction with `aeon` elastic distances. See the [sklearn and\n",
    "aeon distances](../distances/sklearn_distances.ipynb) notebook.\n",
    "\n",
    "- Deep learning based TSCL is a very popular topic, and we are working on bringing\n",
    "deep learning functionality to `aeon`, first algorithms for  [Deep learning] are\n",
    "COMING  SOON\n",
    "\n",
    "- Bespoke feature based TSCL algorithms are easily constructed with `aeon`\n",
    "transformers and `sklearn` clusterers in a pipeline. Some examples are in the\n",
    "[sklearn clustering](feature_clustering.ipynb). We will bring the bespoke feature\n",
    "based clustering algorithms into `aeon` in the medium term.\n",
    "\n",
    "We are in the process of extending the bake off described in [1] to include all\n",
    "clusterers. So far, we find medoids with MSM distance is the best performer.\n",
    "\n",
    "<img src=\"img/clst_cd.png\" width=\"600\" alt=\"cd_diag\">\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "[1] Christopher Holder, Matthew Middlehurst, and Anthony Bagnall. A Review and\n",
    "Evaluation of Elastic Distance Functions for Time Series Clustering,  Knowledge and\n",
    "Information Systems. In Press (2023)\n",
    "\n",
    "[2] J. MacQueen et al. Some methods for classification and analysis of multivariate\n",
    "observations. In Proceedings of the fifth Berkeley symposium on mathematical\n",
    "statistics and probability, volume 1, pages 281–297, 1967\n",
    "\n",
    "[3] J. Yang and J. Leskovec. Patterns of temporal variation in online media. In\n",
    "Proceedings of the Fourth ACM International Conference on Web Search and Data Mining,\n",
    "    WSDM’11, page 177–186, 2011.\n",
    "\n",
    "[4] F. Petitjean, A. Ketterlin, and P. Gancarski. A global averaging method for dynamic\n",
    "time warping, with applications to clustering. Pattern Recognition, 44:678–, 03 2011\n",
    "\n",
    "[5] I. S. Dhillon, Y. Guan, and B. Kulis. Kernel k-means: Spectral clustering and\n",
    "normalized cuts. In Proceedings of the Tenth ACM SIGKDD International Conference on\n",
    "Knowledge Discovery and Data Mining, 2004\n",
    "\n",
    "[6] J. Paparrizos and L. Gravano. k-shape: Efficient and accurate clustering of time\n",
    "series. In Proceedings of the 2015 ACM SIGMOD International Conference on Management\n",
    "of Data, pages 1855–1870, 2015\n",
    "\n",
    "[7] J. Paparrizos and L. Gravano. Fast and accurate time-series clustering. ACM\n",
    "Transactions on Database Systems (TODS), 42(2):1–49, 2017\n",
    "\n",
    "[8] P. J. R. Leonard Kaufman. Partitioning Around Medoids (Program PAM), chapter 2,\n",
    "pages 68–125. John Wiley and Sons, Ltd, 1990\n",
    "\n",
    "[9] L. Kaufman and P. J. Rousseeuw. Clustering large data sets. In Pattern Recognition\n",
    "in Practice, pages 425–437, 1986\n",
    "\n",
    "[10] R. Ng and J. Han. CLARANS: A method for clustering objects for spatial data mining.\n",
    "Knowledge and Data Engineering, IEEE Transactions on, 14:1003– 1016, 10 2002\n",
    "\n",
    "[11] S. P. Lloyd. Least squares quantization in pcm. IEEE Trans. Inf. Theory, 28:129–136,\n",
    "1982\n",
    "\n",
    "[12] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for\n",
    "discovering clusters in large spatial databases with noise. In Proceedings of the\n",
    "Second International Conference on Knowledge Discovery and Data Mining, KDD’96, page\n",
    "226–231, 1996\n",
    "\n",
    "[13] L. McInnes and J. Healy. Accelerated hierarchical density based clustering. IEEE\n",
    " International Conference on Data Mining Workshops (ICDMW), pages 33–42, 2017\n",
    "\n",
    "[14] M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. Optics: Ordering points to\n",
    "identify the clustering structure. SIGMOD Rec., 28(2):49–60, 1999\n",
    "\n",
    "[15] T. Zhang, R. Ramakrishnan, and M. Livny. Birch: An efficient data clustering method\n",
    "for very large databases. SIGMOD Rec., 25(2):103–114, June 1996\n",
    "\n",
    "[16] J. H. W. Jr. Hierarchical grouping to optimize an objective function. Journal of\n",
    " the American Statistical Association, 58(301):236–244, 1963\n",
    "\n",
    "[17] T. R ̈as ̈anen and M. Kolehmainen. Feature-based clustering for electricity use\n",
    "time series data. volume 5495, 2009\n",
    "\n",
    "[18] J. Zakaria, A. Mueen, and E. Keogh. Clustering time series using unsupervised-\n",
    "shapelets. In 2012 IEEE 12th International Conference on Data Mining, pages 785–794,\n",
    "2012\n",
    "\n",
    "[19] Q. Zhang, J. Wu, P. Zhang, G. Long, and C. Zhang. Salient subsequence learning for\n",
    "time series clustering. IEEE Transactions on Pattern Analysis and Machine Intelli-\n",
    "gence, 41(9):2193–2207, 2019\n",
    "\n",
    "[20] L. Shi, L. Du, and Y.-D. Shen. Robust spectral learning for unsupervised feature\n",
    " selection. In 2014 IEEE International Conference on Data Mining, pages 977–982, 2014\n",
    "\n",
    "[21] Z. Li, Y. Yang, J. Liu, X. Zhou, and H. Lu. Unsupervised feature selection using\n",
    "nonnegative spectral analysis. In Proceedings of the Twenty-Sixth AAAI Conference on\n",
    "Artificial Intelligence, AAAI’12, page 1026–1032. AAAI Press, 2012\n",
    "\n",
    "[22] B. Lafabregue, J. Weber, P. Gancarski, and G. Forestier. End-to-end deep\n",
    "representation learning for time series clustering: a comparative study. Data Mining\n",
    "and Knowledge Discovery, 36:29—-81, 2022\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
