{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance based time series classification in aeon\n",
    "\n",
    "Distance based classifiers use a time series specific distance function to measure the\n",
    "similarity between time series. Time series distance functions are\n",
    "often called elastic distances, since they compensate for possible misalignment\n",
    "between series by shifting or editing the series.\n",
    "\n",
    " Dynamic time warping is the best\n",
    "known elastic distance measure. This image\n",
    "demonstrates how a warping path is found between two series\n",
    "<img src=\"./img/dtw.png\" width=\"400\" alt=\"A visualisation of dynamic time warping\">\n",
    "\n",
    "We have a range of elastic distance functions in the distances module. Please see the\n",
    " [distance notebook](../distances/distances.ipynb) for more information.\n",
    " Distance functions have been mostly used with a nearest neighbour (NN) classifier,\n",
    " but you can use them with  [sklearn and aeon distances](../distances/sklearn_distances.ipynb)\n",
    "\n",
    "<img src=\"./img/dtw2.png\" width=\"400\" alt=\"Example of warping two series to the best\n",
    "alignment.\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and list distance based classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:11.686582Z",
     "iopub.status.busy": "2020-12-19T14:30:11.686095Z",
     "iopub.status.idle": "2020-12-19T14:30:12.406787Z",
     "shell.execute_reply": "2020-12-19T14:30:12.407326Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.random.bit_generator'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m metrics\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maeon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_italy_power_demand\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maeon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mregistry\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m all_estimators\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\sklearn\\__init__.py:82\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _distributor_init  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __check_build  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m---> 82\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_show_versions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m show_versions\n\u001B[0;32m     85\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalibration\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcluster\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshow_versions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    129\u001B[0m ]\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\sklearn\\base.py:17\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_config\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _IS_32BIT\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_set_output\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _SetOutputMixin\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tags\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     20\u001B[0m     _DEFAULT_TAGS,\n\u001B[0;32m     21\u001B[0m )\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:25\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeprecation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deprecated\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscovery\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m all_estimators\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfixes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_version, threadpool_info\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_estimator_html_repr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m estimator_html_repr\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvalidation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     28\u001B[0m     as_float_array,\n\u001B[0;32m     29\u001B[0m     assert_all_finite,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     38\u001B[0m     _is_arraylike_not_scalar,\n\u001B[0;32m     39\u001B[0m )\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py:19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mthreadpoolctl\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeprecation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deprecated\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\scipy\\stats\\__init__.py:453\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m.. _statsrefmanual:\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    450\u001B[0m \n\u001B[0;32m    451\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 453\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stats_py\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_variation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m variation\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\scipy\\stats\\_stats_py.py:44\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecial\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mspecial\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m linalg\n\u001B[1;32m---> 44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distributions\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _mstats_basic \u001B[38;5;28;01mas\u001B[39;00m mstats_basic\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stats_mstats_common\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (_find_repeats, linregress, theilslopes,\n\u001B[0;32m     47\u001B[0m                                    siegelslopes)\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\scipy\\stats\\distributions.py:11\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_distn_infrastructure\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (rv_discrete, rv_continuous, rv_frozen)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _continuous_distns\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _discrete_distns\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_continuous_distns\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_discrete_distns\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32mC:\\Code\\aeon\\venv\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py:21\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_distn_infrastructure\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     18\u001B[0m     rv_discrete, _ncx2_pdf, _ncx2_cdf, get_distribution_names,\n\u001B[0;32m     19\u001B[0m     _check_shape)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_boost\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_boost\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_biasedurn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (_PyFishersNCHypergeometric,\n\u001B[0;32m     22\u001B[0m                         _PyWalleniusNCHypergeometric,\n\u001B[0;32m     23\u001B[0m                         _PyStochasticLib3)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mbinom_gen\u001B[39;00m(rv_discrete):\n\u001B[0;32m     26\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"A binomial discrete random variable.\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \n\u001B[0;32m     28\u001B[0m \u001B[38;5;124;03m    %(before_notes)s\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     51\u001B[0m \n\u001B[0;32m     52\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m_biasedurn.pyx:1\u001B[0m, in \u001B[0;36minit scipy.stats._biasedurn\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'numpy.random.bit_generator'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from aeon.datasets import load_italy_power_demand\n",
    "from aeon.registry import all_estimators\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "all_estimators(\"classifier\", filter_tags={\"algorithm_type\": \"distance\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Distance based classifiers\n",
    "The data was derived from twelve monthly electrical power demand time series from Italy and first used in the paper \"Intelligent Icons: Integrating Lite-Weight Data Mining and Visualization into GUI Operating Systems\". The classification task is to distinguish days from Oct to March (inclusive) from April to September.\n",
    "\n",
    "The dataset consists of 1096 rows in total. Each row represents a day of Italys electric power consumption. All days have a label either 1 or 2. 67 rows are used for training and the rest are for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_italy_power_demand(split=\"train\", return_X_y=True)\n",
    "X_test, y_test = load_italy_power_demand(split=\"test\", return_X_y=True)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "axs[1, 1].axis(\"off\")\n",
    "axs[1, 0].axis(\"off\")\n",
    "ax_combined = fig.add_subplot(2, 1, (2, 3))\n",
    "axs[0, 0].set_title(\"All days class 1\")\n",
    "axs[0, 1].set_title(\"All days class 2\")\n",
    "ax_combined.set_title(\"Both classes on top of each other\")\n",
    "for i in np.where(y_test == \"1\")[0]:\n",
    "    axs[0, 0].plot(X_test[i][0], alpha=0.1, color=\"cornflowerblue\", linestyle=\"solid\")\n",
    "    ax_combined.plot(X_test[i][0], alpha=0.1, color=\"cornflowerblue\", linestyle=\"--\")\n",
    "for i in np.where(y_test == \"2\")[0]:\n",
    "    axs[0, 1].plot(X_test[i][0], alpha=0.1, color=\"orange\", linestyle=\"solid\")\n",
    "    ax_combined.plot(X_test[i][0], alpha=0.1, color=\"orange\", linestyle=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from aeon.classification.distance_based import (\n",
    "    ElasticEnsemble,\n",
    "    KNeighborsTimeSeriesClassifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## K-NN: KNeighborsTimeSeriesClassifier in aeon\n",
    "k-NN is often called a lazy classifier, because there is little work done in\n",
    "the fit operation. The fit operation simply stores the training data. When we want to\n",
    "make a prediction for a new time series, k-NN measures the distance between the new\n",
    "time series and all the series in the training data and records the class of the\n",
    "closest k train series. The class labels of these nearest neighbours are used to make\n",
    " a prediction: if they are all the same label, then that is the prediction. If they\n",
    " differ, then some form of voting mechanism is required. For example, we may predict\n",
    " the most common class label amongst the nearest neighbours for the test instance.\n",
    "\n",
    "KNeighborsTimeSeriesClassifier in aeon is configurable to use any of the distances\n",
    "functions in the distance module, or it can be passed a bespoke callable. You can set\n",
    "the number of neighbours and the weights. Weights are used in the prediction\n",
    "process when neightbours differ in class values. By default all neighbours have an\n",
    "equal vote. There is an option to weight by distance, meaning closer neighbours have\n",
    "more weight in the vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsTimeSeriesClassifier(distance=\"msm\", n_neighbors=3, weights=\"distance\")\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, knn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Elastic Ensemble: ElasticEnsemble in aeon\n",
    "\n",
    "The first algorithm to significantly out perform 1-NN DTW on the UCR data was the\n",
    "Elastic Ensemble (EE) [1]. EE is a weighted ensemble of 11 1-NN classifiers with a\n",
    "range of elastic distance measures. It was the best performing distance based\n",
    "classifier in the bake off. Elastic distances can be slow, and EE requires cross\n",
    "validation to find the weights of each classifier in the ensemble. You can configure\n",
    "EE to use specified distance functions, and tell it how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ee = ElasticEnsemble(\n",
    "    distance_measures=[\"dtw\", \"msm\"],\n",
    "    proportion_of_param_options=0.1,\n",
    "    proportion_train_in_param_finding=0.3,\n",
    "    proportion_train_for_test=0.5,\n",
    ")\n",
    "ee.fit(X_train, y_train)\n",
    "ee_preds = ee.predict(X_test)\n",
    "metrics.accuracy_score(y_test, ee_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Proximity Forest\n",
    "\n",
    "Proximity Forest [2] is a distance based ensemble of decision trees. Its is the\n",
    "most accurate purely distance based technique for TSC that we know of. We do not\n",
    "currently have a working version of PF in aeon, but would very much like to have one.\n",
    "please see this issue. https://github.com/aeon-toolkit/aeon/issues/159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Performance on the UCR univariate datasets\n",
    "You can find the dictionary based classifiers as follows. Note we do not have a\n",
    "Proximity Forest implementation in aeon yet, but we do have the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from aeon.registry import all_estimators\n",
    "\n",
    "est = all_estimators(\"classifier\", filter_tags={\"algorithm_type\": \"distance\"})\n",
    "for c in est:\n",
    "    print(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from aeon.benchmarking import get_estimator_results_as_array\n",
    "from aeon.datasets.tsc_datasets import univariate\n",
    "\n",
    "names = [t[0].replace(\"Classifier\", \"\") for t in est]\n",
    "names.append(\n",
    "    \"PF\"\n",
    ")  # Results from Java implementation, as are the ElasticEnsemble results\n",
    "\n",
    "results, present_names = get_estimator_results_as_array(\n",
    "    names, univariate, include_missing=False\n",
    ")\n",
    "results.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from aeon.visualisation import plot_boxplot_median, plot_critical_difference\n",
    "\n",
    "plot_critical_difference(results, names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_boxplot_median(results, names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Lines J, Bagnall A (2015) Time series classification with ensembles of elastic\n",
    "distance measures. Data Mining and Knowledge Discovery 29:565–592\n",
    "\n",
    "[2] Lucas et al. (2019) Proximity Forest: an effective and scalable distance-based\n",
    "classifier. Data Mining and Knowledge Discovery 33: 607--635 https://arxiv.org/abs/1808.10594\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
