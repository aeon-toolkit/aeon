{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dictionary based time series classification in sktime\n",
    "\n",
    "Dictionary based approaches adapt the bag of words model commonly used in signal processing, computer vision and audio processing for time series classification. Like shapelet based algorithms, dictionary approaches use phase-independent subsequences by sliding a window over time series. However, rather than to measure the distance to a subsequence, as in shapelets, each window is transformed into a word, and the frequency of occurrence of repeating patterns is recorded. Algorithms following the dictionary model build a classifier by:\n",
    "\n",
    "Extracting subsequences, aka windows, from a time series;\n",
    "1. Transforming each window of real values into a discrete-valued \\emph{word} (a sequence of symbols over a fixed alphabet);\n",
    "2. Building a sparse feature vector of histograms of word counts, and\n",
    "3. Finally using a classification method from the machine learning repertoire on these feature vectors.\n",
    "The figure illustrates these steps from a raw time series to a dictionary model using overlapping windows.\n",
    "<img src=\"./img/dictionary.png\" width=\"600\" alt=\"Dictionary based time series classification\"> [<i>&#x200B;</i>](./img/tsc.png)\n",
    "\n",
    "Dictionary-based methods differ in the way they transform a window of real-valued measurements into discrete words (discretization). Many methods are based on a symbolic representation called SFA. To create a discrete word from a window of continuous values in a series, SFA follows the following steps:\n",
    "1. Values in each window are normalized to have standard deviation of 1.\n",
    "2. The dimensionality of each normalized window reduced by the use of the truncated Fourier transform. The window is transformed using as fast Fourier transform, and only the first few coefficients are retained.\n",
    "3. Each coefficient is discretized into a symbol from an alphabet a fixed size to form a word\n",
    "\n",
    "Creating words from windows requires three parameters:\n",
    "1. 'window_size' specifies how long each window is.\n",
    "2. 'length' specifies the reduced series length in step 2.\n",
    "3. 'alphabet_size' is the number of letters in the alphabet used in step 3.\n",
    "\n",
    "These core parameters are often fixed internally. There are currently four dictionary based classifiers implemented in sktime, all making use of the Symbolic Fourier Approximation (SFA) \\[1\\] transform to discretise into words. These are the Bag of SFA Symbols (BOSS) \\[2\\], the Contractable Bag of SFA Symbols (cBOSS) \\[3\\], Word Extraction for Time Series Classification  (WEASEL) \\[4\\] and the Temporal Dictionary Ensemble (TDE) \\[5\\]. WEASEL has a multivariate extension called MUSE \\[7\\] and TDE has multivariate capability. We summarise their characteristics and give example usage in this notebook. More technical details are available in \\[8\\].\n",
    "\n",
    "\n",
    "## Imports and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:11.686582Z",
     "iopub.status.busy": "2020-12-19T14:30:11.686095Z",
     "iopub.status.idle": "2020-12-19T14:30:12.406787Z",
     "shell.execute_reply": "2020-12-19T14:30:12.407326Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 1, 24) (67,) (50, 1, 24) (50,)\n",
      "(20, 6, 100) (20,) (20, 6, 100) (20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sktime.classification.dictionary_based import (\n",
    "    IndividualBOSS,\n",
    "    BOSSEnsemble,\n",
    "    ContractableBOSS,\n",
    "    MUSE,\n",
    "    WEASEL,\n",
    "    TemporalDictionaryEnsemble,\n",
    ")\n",
    "from sktime.datasets import load_basic_motions, load_italy_power_demand\n",
    "\n",
    "X_train, y_train = load_italy_power_demand(split=\"train\")\n",
    "X_test, y_test = load_italy_power_demand(split=\"test\")\n",
    "X_test = X_test[:50]\n",
    "y_test = y_test[:50]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "X_train_mv, y_train_mv = load_basic_motions(split=\"train\")\n",
    "X_test_mv, y_test_mv = load_basic_motions(split=\"test\")\n",
    "\n",
    "X_train_mv = X_train_mv[:20]\n",
    "y_train_mv = y_train_mv[:20]\n",
    "X_test_mv = X_test_mv[:20]\n",
    "y_test_mv = y_test_mv[:20]\n",
    "\n",
    "print(X_train_mv.shape, y_train_mv.shape, X_test_mv.shape, y_test_mv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bag of SFA Symbols (BOSS): `IndividualBOSS`, `BOSSEnsemble` and `cBOSS`\n",
    "\n",
    "BOSS is an ensemble of individual BOSS classifiers making use of the SFA transform. `IndividualBOSS` has arguments for `window_size` ($w$) default 10, `word_length` ($l$), default 8, and `alphabet_size` ($\\alpha$), default 4. Algorithms that use the `IndividualBOSS` classifier use ensembles that diversify their members through changing their parameters.\n",
    "\n",
    "The `BOSSEnsemble` classifier is an ensemble of `IndividualBOSS` classifiers. It performs grid-search through a large number of combinations of `window_size` (default 10), `word_length` (default 8) and `alphabet_size`(boolean normalise each window) parameters. Of the classifiers searched only those within 92\\% accuracy of the best classifier are retained. Individual BOSS classifiers use a non-symmetric distance function, BOSS distance, in conjunction with a nearest neighbour classifier. BOSS internally tunes so there are few parameters to be altered. Generally it should be run using default settings.\n",
    "\n",
    "cBOSS significantly speeds up BOSS with no significant difference in accuracy by improving how the ensemble is formed. cBOSS randomly selects a set parameters for $w$, $l$ and $\\alpha$, and keeps the best `max_ensemble_size` `IndividualBOSS` classifiers in the ensemble, where best means highest is estimated accuracy on the train data. The number of `IndividualBOSS` classifiers to keep in the ensemble and the number of randomly generated parameters to test are parameters `max_ensemble_size` (default 50) and `n_parameter_samples` (default 250). The `n_parameter_samples` parameter can be replaced with a maximum run time limit with the parameter `time_limit_in_minutes`. Setting this parameter will make the classifier randomly sample parameters for the specified amount of time. We call this capability contracting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:12.411079Z",
     "iopub.status.busy": "2020-12-19T14:30:12.410605Z",
     "iopub.status.idle": "2020-12-19T14:30:13.198883Z",
     "shell.execute_reply": "2020-12-19T14:30:13.199360Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOSS Accuracy: 0.94\n",
      "cBOSS Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "one_boss = IndividualBOSS(window_size=8, word_length=4, alphabet_size=6)\n",
    "boss = BOSSEnsemble(random_state=47)\n",
    "boss.fit(X_train, y_train)\n",
    "\n",
    "boss_preds = boss.predict(X_test)\n",
    "print(\"BOSS Accuracy: \" + str(metrics.accuracy_score(y_test, boss_preds)))\n",
    "cboss = ContractableBOSS(n_parameter_samples=250, max_ensemble_size=50, random_state=47)\n",
    "cboss.fit(X_train, y_train)\n",
    "\n",
    "cboss_preds = cboss.predict(X_test)\n",
    "print(\"cBOSS Accuracy: \" + str(metrics.accuracy_score(y_test, cboss_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Word Extraction for Time Series Classification (WEASEL)\n",
    "\n",
    "WEASEL transforms time series into feature vectors, using a sliding-window approach, which are then analyzed through a machine learning classifier. The novelty of WEASEL lies in its specific method for deriving features, resulting in a much smaller yet much more discriminative feature set than BOSS. It extends SFA by bigrams, feature selection using Anova-f-test and Information Gain Binning (IGB).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:14.656633Z",
     "iopub.status.busy": "2020-12-19T14:30:14.656058Z",
     "iopub.status.idle": "2020-12-19T14:30:15.042508Z",
     "shell.execute_reply": "2020-12-19T14:30:15.042998Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEASEL Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "weasel = WEASEL(binning_strategy=\"equi-depth\", anova=False, random_state=47)\n",
    "weasel.fit(X_train, y_train)\n",
    "\n",
    "weasel_preds = weasel.predict(X_test)\n",
    "print(\"Univariate WEASEL Accuracy on ItalyPowerDemand: \" + str(metrics.accuracy_score(y_test, weasel_preds)))\n",
    "\n",
    "muse = MUSE()\n",
    "muse.fit(X_train_mv, y_train_mv)\n",
    "\n",
    "muse_preds = muse.predict(X_test_mv)\n",
    "print(\"Multivariate MUSE Accuracy on BasicMotions: \" + str(metrics.accuracy_score(y_test_mv, muse_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Temporal Dictionary Ensemble (TDE)\n",
    "\n",
    "The `TemporalDictionaryEnsemble` (TDE) aggregates the best components of cBOSS and WEASEL with the concept of Spatial Pyramids used in computer vision, first used in this context in an algorithm called Spatial BOSS \\[6\\]. Spatial pyramids split the time series up in to contiguous segments and construct dictionary\n",
    "\n",
    "PICTURE HERE\n",
    "\n",
    "At the top level of the pyramid, the whole series is used. cBOSS like classifiers are built on the whole series that use bigrams and Information Gain Binning (IGB) proposed for WEASEL. At the next level, BOSS like classifiers are built independently on each half of the series. At the third level, quarters of the series are used. Once at the final level, all the\n",
    "\n",
    "The parameter space for the search for the TDE model is much larger, because of the extra parameters. Rather than random search of parameter combinations, after `randomly_selected_params` model evaluations, a Gaussian process regressor is used to select new parameter sets to evaluate for the ensemble, predicting the accuracy of a set of parameter values using past classifier performances. This improves overall performance. Like cBOSS, TDE is contractable, i.e. you can specify the approximate maximum train time with the `time_limit_in_minutes` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:15.049119Z",
     "iopub.status.busy": "2020-12-19T14:30:15.048625Z",
     "iopub.status.idle": "2020-12-19T14:30:24.886051Z",
     "shell.execute_reply": "2020-12-19T14:30:24.886568Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tde_u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 13\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# If you wish to set a time contract to, for example, 5 minutes, set time_limit_in_minutes = 5 in the constructor\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Univariate\u001B[39;00m\n\u001B[0;32m     11\u001B[0m tde\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m---> 13\u001B[0m tde_preds \u001B[38;5;241m=\u001B[39m \u001B[43mtde_u\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTDE Accuracy on Italy Power Demand: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(metrics\u001B[38;5;241m.\u001B[39maccuracy_score(y_test, tde_u_preds)))\n\u001B[0;32m     15\u001B[0m tde\u001B[38;5;241m.\u001B[39mfit(X_train_mv, y_train_mv)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tde_u' is not defined"
     ]
    }
   ],
   "source": [
    "# Recommended non-contract TDE parameters\n",
    "tde = TemporalDictionaryEnsemble(\n",
    "    n_parameter_samples=250,\n",
    "    max_ensemble_size=50,\n",
    "    randomly_selected_params=50,\n",
    "    random_state=47,\n",
    ")\n",
    "\n",
    "# If you wish to set a time contract to, for example, 5 minutes, set time_limit_in_minutes = 5 in the constructor\n",
    "# Univariate\n",
    "tde.fit(X_train, y_train)\n",
    "\n",
    "tde_preds = tde.predict(X_test)\n",
    "print(\"TDE Accuracy on ItalyPowerDemand: \" + str(metrics.accuracy_score(y_test, tde_preds)))\n",
    "tde.fit(X_train_mv, y_train_mv)\n",
    "\n",
    "tde_preds = tde.predict(X_test_mv)\n",
    "print(\"TDE Accuracy on BasicMotions: \" + str(metrics.accuracy_score(y_test_mv, tde_preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### References:\n",
    "\n",
    "\\[1\\] Schäfer, P., & Högqvist, M. (2012). SFA: a symbolic fourier approximation and index for similarity search in high dimensional datasets. In Proceedings of the 15th International Conference on Extending Database Technology (pp. 516-527).\n",
    "\n",
    "\\[2\\] Schäfer, P. (2015). The BOSS is concerned with time series classification in the presence of noise. Data Mining and Knowledge Discovery, 29(6), 1505-1530.\n",
    "\n",
    "\\[3\\] Middlehurst, M., Vickers, W., & Bagnall, A. (2019). Scalable dictionary classifiers for time series classification. In International Conference on Intelligent Data Engineering and Automated Learning (pp. 11-19). Springer, Cham.\n",
    "\n",
    "\\[4\\] Schäfer, P., & Leser, U. (2017). Fast and accurate time series classification with WEASEL. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (pp. 637-646).\n",
    "\n",
    "\\[5\\] Middlehurst, M., Large, J., Cawley, G., & Bagnall, A. (2020). The Temporal Dictionary Ensemble (TDE) Classifier for Time Series Classification. In The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases.\n",
    "\n",
    "\\[6\\] Large, J., Bagnall, A., Malinowski, S., & Tavenard, R. (2019). On time series classification with dictionary-based classifiers. Intelligent Data Analysis, 23(5), 1073-1089.\n",
    "\n",
    "\\[7\\] Schäfer, P., & Leser, U. (2018). Multivariate time series classification with WEASEL+MUSE. 3rd ECML/PKDD Workshop on AALTD.\n",
    "\n",
    "\\[8\\] Middlehurst, M., Schäfer, P., & Bagnall, A. (2023). Bake off redux. COMING SOON TO AN ARXIV NEAR YOU!."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}