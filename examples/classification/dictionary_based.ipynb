{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dictionary based time series classification in sktime\n",
    "\n",
    "Dictionary based approaches adapt the bag of words model commonly used in signal processing, computer vision and audio processing for time series classification. Like shapelet based algorithms, dictionary approaches use phase-independent subsequences by sliding a window over time series. However, rather than to measure the distance to a subsequence, as in shapelets, each window is transformed into a word, and the frequency of occurrence of repeating patterns is recorded. Algorithms following the dictionary model build a classifier by:\n",
    "\n",
    "Extracting subsequences, aka windows, from a time series;\n",
    "1. Transforming each window of real values into a discrete-valued \\emph{word} (a sequence of symbols over a fixed alphabet);\n",
    "2. Building a sparse feature vector of histograms of word counts, and\n",
    "3. Finally using a classification method from the machine learning repertoire on these feature vectors.\n",
    "The figure illustrates these steps from a raw time series to a dictionary model using overlapping windows.\n",
    "<img src=\"./img/dictionary.png\" width=\"600\" alt=\"Dictionary based time series classification\"> [<i>&#x200B;</i>](./img/tsc.png)\n",
    "\n",
    "Dictionary-based methods differ in the way they transform a window of real-valued measurements into discrete words (discretization). Many methods are based on a symbolic representation called SFA. To create a discrete word from a window of continuous values in a series, SFA follows the following steps:\n",
    "1. Values in each window are normalized to have standard deviation of 1.\n",
    "2. The dimensionality of each normalized window reduced by the use of the truncated Fourier transform. The window is transformed using as fast Fourier transform, and only the first few coefficients are retained.\n",
    "3. Each coefficient is discretized into a symbol from an alphabet a fixed size to form a word\n",
    "\n",
    "Creating words from windows requires three parameters:\n",
    "1. 'window_size' specifies how long each window is.\n",
    "2. 'length' specifies the reduced series length in step 2.\n",
    "3. 'alphabet_size' is the number of letters in the alphabet used in step 3.\n",
    "\n",
    "These core parameters are often fixed internally. There are currently four dictionary based classifiers implemented in sktime, all making use of the Symbolic Fourier Approximation (SFA) \\[1\\] transform to discretise into words. These are the Bag of SFA Symbols (BOSS) \\[2\\], the Contractable Bag of SFA Symbols (cBOSS) \\[3\\], Word Extraction for Time Series Classification  (WEASEL) \\[4\\] and the Temporal Dictionary Ensemble (TDE) \\[5\\]. WEASEL has a multivariate extension called MUSE \\[7\\] and TDE has multivariate capability. We summarise their characteristics and give example usage in this notebook. More technical details are available in \\[8\\].\n",
    "\n",
    "\n",
    "## 1. Imports and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:11.686582Z",
     "iopub.status.busy": "2020-12-19T14:30:11.686095Z",
     "iopub.status.idle": "2020-12-19T14:30:12.406787Z",
     "shell.execute_reply": "2020-12-19T14:30:12.407326Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 1, 24) (67,) (50, 1, 24) (50,)\n",
      "(20, 6, 100) (20,) (20, 6, 100) (20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sktime.classification.dictionary_based import (\n",
    "    IndividualBOSS,\n",
    "    BOSSEnsemble,\n",
    "    ContractableBOSS,\n",
    "    MUSE,\n",
    "    WEASEL,\n",
    "    TemporalDictionaryEnsemble,\n",
    ")\n",
    "from sktime.datasets import load_basic_motions, load_italy_power_demand\n",
    "\n",
    "X_train, y_train = load_italy_power_demand(split=\"train\")\n",
    "X_test, y_test = load_italy_power_demand(split=\"test\")\n",
    "X_test = X_test[:50]\n",
    "y_test = y_test[:50]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "X_train_mv, y_train_mv = load_basic_motions(split=\"train\")\n",
    "X_test_mv, y_test_mv = load_basic_motions(split=\"test\")\n",
    "\n",
    "X_train_mv = X_train_mv[:20]\n",
    "y_train_mv = y_train_mv[:20]\n",
    "X_test_mv = X_test_mv[:20]\n",
    "y_test_mv = y_test_mv[:20]\n",
    "\n",
    "print(X_train_mv.shape, y_train_mv.shape, X_test_mv.shape, y_test_mv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Bag of SFA Symbols (BOSS): `IndividualBOSS`, `BOSSEnsemble` and `cBOSS`\n",
    "\n",
    "BOSS is an ensemble of individual BOSS classifiers making use of the SFA transform. `IndividualBOSS` has arguments for `window_size` ($w$) default 10, `word_length` ($l$), default 8, and `alphabet_size` ($\\alpha$), default 4. Algorithms that use the `IndividualBOSS` classifier use ensembles that diversify their members through changing their parameters.\n",
    "\n",
    "The `BOSSEnsemble` classifier is an ensemble of `IndividualBOSS` classifiers. It performs grid-search through a large number of combinations of `window_size` (default 10), `word_length` (default 8) and `alphabet_size`(boolean normalise each window) parameters. Of the classifiers searched only those within 92\\% accuracy of the best classifier are retained. Individual BOSS classifiers use a non-symmetric distance function, BOSS distance, in conjunction with a nearest neighbour classifier. BOSS internally tunes so there are few parameters to be altered. Generally it should be run using default settings.\n",
    "\n",
    "cBOSS significantly speeds up BOSS with no significant difference in accuracy by improving how the ensemble is formed. cBOSS randomly selects a set parameters for $w$, $l$ and $\\alpha$, and keeps the best `max_ensemble_size` `IndividualBOSS` classifiers in the ensemble, where best means highest is estimated accuracy on the train data. The number of `IndividualBOSS` classifiers to keep in the ensemble and the number of randomly generated parameters to test are parameters `max_ensemble_size` (default 50) and `n_parameter_samples` (default 250). The `n_parameter_samples` parameter can be replaced with a maximum run time limit with the parameter `time_limit_in_minutes`. Setting this parameter will make the classifier randomly sample parameters for the specified amount of time. We call this capability contracting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:12.411079Z",
     "iopub.status.busy": "2020-12-19T14:30:12.410605Z",
     "iopub.status.idle": "2020-12-19T14:30:13.198883Z",
     "shell.execute_reply": "2020-12-19T14:30:13.199360Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOSS Accuracy: 0.94\n",
      "cBOSS Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "one_boss = IndividualBOSS(window_size=8, word_length=4, alphabet_size=6)\n",
    "boss = BOSSEnsemble(random_state=47)\n",
    "boss.fit(X_train, y_train)\n",
    "\n",
    "boss_preds = boss.predict(X_test)\n",
    "print(\"BOSS Accuracy: \" + str(metrics.accuracy_score(y_test, boss_preds)))\n",
    "cboss = ContractableBOSS(n_parameter_samples=250, max_ensemble_size=50, random_state=47)\n",
    "cboss.fit(X_train, y_train)\n",
    "\n",
    "cboss_preds = cboss.predict(X_test)\n",
    "print(\"cBOSS Accuracy: \" + str(metrics.accuracy_score(y_test, cboss_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Word Extraction for Time Series Classification (WEASEL)\n",
    "\n",
    "WEASEL transforms time series into feature vectors, using a sliding-window approach, which are then analyzed through a machine learning classifier. The novelty of WEASEL lies in its specific method for deriving features, resulting in a much smaller yet much more discriminative feature set than BOSS. It extends SFA by bigrams, feature selection using Anova-f-test and Information Gain Binning (IGB).\n",
    "\n",
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:14.656633Z",
     "iopub.status.busy": "2020-12-19T14:30:14.656058Z",
     "iopub.status.idle": "2020-12-19T14:30:15.042508Z",
     "shell.execute_reply": "2020-12-19T14:30:15.042998Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEASEL Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "weasel = WEASEL(binning_strategy=\"equi-depth\", anova=False, random_state=47)\n",
    "weasel.fit(X_train, y_train)\n",
    "\n",
    "weasel_preds = weasel.predict(X_test)\n",
    "print(\"WEASEL Accuracy: \" + str(metrics.accuracy_score(y_test, weasel_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multivariate\n",
    "\n",
    "WEASEL+MUSE (Multivariate Symbolic Extension) is the multivariate extension of WEASEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m muse \u001B[38;5;241m=\u001B[39m MUSE()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmuse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m muse_preds \u001B[38;5;241m=\u001B[39m muse\u001B[38;5;241m.\u001B[39mpredict(X_test_mv)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMUSE Accuracy: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(metrics\u001B[38;5;241m.\u001B[39maccuracy_score(y_test_mv, muse_preds)))\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\sktime\\classification\\base.py:192\u001B[0m, in \u001B[0;36mBaseClassifier.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    187\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    188\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself.n_jobs must be set if capability:multithreading is True\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    189\u001B[0m         )\n\u001B[0;32m    191\u001B[0m \u001B[38;5;66;03m# pass coerced and checked data to inner _fit\u001B[39;00m\n\u001B[1;32m--> 192\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_time_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mround\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)) \u001B[38;5;241m-\u001B[39m start\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# this should happen last\u001B[39;00m\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\sktime\\classification\\dictionary_based\\_muse.py:201\u001B[0m, in \u001B[0;36mMUSE._fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvariance \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manova:\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMUSE Warning: Please set either variance or anova.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 201\u001B[0m parallel_res \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_fit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# no clue why, but this copy is required.\u001B[39;49;00m\n\u001B[0;32m    205\u001B[0m \u001B[43m        \u001B[49m\u001B[43mind\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin_window\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_window\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow_inc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mword_lengths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malphabet_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manova\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvariance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinning_strategies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbigrams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mp_threshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_selection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mind\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_dims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mSFA_transformers \u001B[38;5;241m=\u001B[39m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])]\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_sizes \u001B[38;5;241m=\u001B[39m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])]\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\joblib\\parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\sktime\\classification\\dictionary_based\\_muse.py:443\u001B[0m, in \u001B[0;36m_parallel_fit\u001B[1;34m(X, y, ind, min_window, max_window, window_inc, word_lengths, alphabet_size, norm_options, anova, variance, binning_strategies, bigrams, n_jobs, p_threshold, feature_selection, random_state)\u001B[0m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m window_size \u001B[38;5;129;01min\u001B[39;00m window_sizes:\n\u001B[0;32m    424\u001B[0m     transformer \u001B[38;5;241m=\u001B[39m SFAFast(\n\u001B[0;32m    425\u001B[0m         word_length\u001B[38;5;241m=\u001B[39mrng\u001B[38;5;241m.\u001B[39mchoice(word_lengths),\n\u001B[0;32m    426\u001B[0m         alphabet_size\u001B[38;5;241m=\u001B[39malphabet_size,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m         return_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    441\u001B[0m     )\n\u001B[1;32m--> 443\u001B[0m     all_words\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    444\u001B[0m     SFA_transformers\u001B[38;5;241m.\u001B[39mappend(transformer)\n\u001B[0;32m    445\u001B[0m     relevant_features_count \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfeature_count\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\sktime\\transformations\\panel\\dictionary_based\\_sfa_fast.py:306\u001B[0m, in \u001B[0;36mSFAFast.fit_transform\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    303\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwords \u001B[38;5;241m=\u001B[39m words\n\u001B[0;32m    305\u001B[0m \u001B[38;5;66;03m# fitting: learns the feature selection strategy, too\u001B[39;00m\n\u001B[1;32m--> 306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform_to_bag\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mword_length_actual\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\sktime\\transformations\\panel\\dictionary_based\\_sfa_fast.py:459\u001B[0m, in \u001B[0;36mSFAFast.transform_to_bag\u001B[1;34m(self, words, word_len, y)\u001B[0m\n\u001B[0;32m    449\u001B[0m bag_of_words, _ \u001B[38;5;241m=\u001B[39m create_bag_feature_selection(\n\u001B[0;32m    450\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_index,\n\u001B[0;32m    451\u001B[0m     words\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    455\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mremove_repeat_words,\n\u001B[0;32m    456\u001B[0m )\n\u001B[0;32m    458\u001B[0m \u001B[38;5;66;03m# apply chi2-based feature selection\u001B[39;00m\n\u001B[1;32m--> 459\u001B[0m chi2_statistics, p \u001B[38;5;241m=\u001B[39m \u001B[43mchi2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbag_of_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;66;03m# p-threshold using 'p_threshold'\u001B[39;00m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_selection \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchi2\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:239\u001B[0m, in \u001B[0;36mchi2\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m    236\u001B[0m class_prob \u001B[38;5;241m=\u001B[39m Y\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    237\u001B[0m expected \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(class_prob\u001B[38;5;241m.\u001B[39mT, feature_count)\n\u001B[1;32m--> 239\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_chisquare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexpected\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\code\\scikit-time\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:167\u001B[0m, in \u001B[0;36m_chisquare\u001B[1;34m(f_obs, f_exp)\u001B[0m\n\u001B[0;32m    165\u001B[0m     chisq \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m f_exp\n\u001B[0;32m    166\u001B[0m chisq \u001B[38;5;241m=\u001B[39m chisq\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m chisq, \u001B[43mspecial\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchdtrc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchisq\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "muse = MUSE()\n",
    "muse.fit(X_train_mv, y_train_mv)\n",
    "\n",
    "muse_preds = muse.predict(X_test_mv)\n",
    "print(\"MUSE Accuracy: \" + str(metrics.accuracy_score(y_test_mv, muse_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Temporal Dictionary Ensemble (TDE)\n",
    "\n",
    "TDE aggregates the best components of 3 classifiers extending from the original BOSS algorithm. The ensemble structure and improvements of cBOSS\\[3\\] are used; Spatial pyramids are introduced from Spatial BOSS (S-BOSS)\\[6\\]; From Word Extraction for Time Series Classification (WEASEL)\\[4\\] bigrams and Information Gain Binning (IGB), a replacement for the multiple coefficient binning (MCB) used by SFA, are included.\n",
    "Two new parameters are included in the ensemble parameter search, the number of spatial pyramid levels $h$ and whether to use IGB or MCB $b$.\n",
    "A Gaussian processes regressor is used to select new parameter sets to evaluate for the ensemble, predicting the accuracy of a set of parameter values using past classifier performances.\n",
    "\n",
    "Inheriting the cBOSS ensemble structure, the number of parameter samples $k$, time limit $t$ and max ensemble size $s$ remain as parameters to be set accounting for memory and time requirements.\n",
    "\n",
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:30:15.049119Z",
     "iopub.status.busy": "2020-12-19T14:30:15.048625Z",
     "iopub.status.idle": "2020-12-19T14:30:24.886051Z",
     "shell.execute_reply": "2020-12-19T14:30:24.886568Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Recommended non-contract TDE parameters\n",
    "tde_u = TemporalDictionaryEnsemble(\n",
    "    n_parameter_samples=250,\n",
    "    max_ensemble_size=50,\n",
    "    randomly_selected_params=50,\n",
    "    random_state=47,\n",
    ")\n",
    "\n",
    "# TDE with a 1 minute build time contract\n",
    "# tde = TemporalDictionaryEnsemble(time_limit_in_minutes=1,\n",
    "#                                 max_ensemble_size=50,\n",
    "#                                 randomly_selected_params=50,\n",
    "#                                 random_state=47)\n",
    "\n",
    "tde_u.fit(X_train, y_train)\n",
    "\n",
    "tde_u_preds = tde_u.predict(X_test)\n",
    "print(\"TDE Accuracy: \" + str(metrics.accuracy_score(y_test, tde_u_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Recommended non-contract TDE parameters\n",
    "tde_mv = TemporalDictionaryEnsemble(\n",
    "    n_parameter_samples=250,\n",
    "    max_ensemble_size=50,\n",
    "    randomly_selected_params=50,\n",
    "    random_state=47,\n",
    ")\n",
    "\n",
    "# TDE with a 1 minute build time contract\n",
    "# tde_m = TemporalDictionaryEnsemble(time_limit_in_minutes=1,\n",
    "#                                 max_ensemble_size=50,\n",
    "#                                 randomly_selected_params=50,\n",
    "#                                 random_state=47)\n",
    "\n",
    "tde_mv.fit(X_train_mv, y_train_mv)\n",
    "\n",
    "tde_mv_preds = tde_mv.predict(X_test_mv)\n",
    "print(\"TDE Accuracy: \" + str(metrics.accuracy_score(y_test_mv, tde_mv_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### References:\n",
    "\n",
    "\\[1\\] Schäfer, P., & Högqvist, M. (2012). SFA: a symbolic fourier approximation and index for similarity search in high dimensional datasets. In Proceedings of the 15th International Conference on Extending Database Technology (pp. 516-527).\n",
    "\n",
    "\\[2\\] Schäfer, P. (2015). The BOSS is concerned with time series classification in the presence of noise. Data Mining and Knowledge Discovery, 29(6), 1505-1530.\n",
    "\n",
    "\\[3\\] Middlehurst, M., Vickers, W., & Bagnall, A. (2019). Scalable dictionary classifiers for time series classification. In International Conference on Intelligent Data Engineering and Automated Learning (pp. 11-19). Springer, Cham.\n",
    "\n",
    "\\[4\\] Schäfer, P., & Leser, U. (2017). Fast and accurate time series classification with WEASEL. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (pp. 637-646).\n",
    "\n",
    "\\[5\\] Middlehurst, M., Large, J., Cawley, G., & Bagnall, A. (2020). The Temporal Dictionary Ensemble (TDE) Classifier for Time Series Classification. In The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases.\n",
    "\n",
    "\\[6\\] Large, J., Bagnall, A., Malinowski, S., & Tavenard, R. (2019). On time series classification with dictionary-based classifiers. Intelligent Data Analysis, 23(5), 1073-1089.\n",
    "\n",
    "\\[7\\] Schäfer, P., & Leser, U. (2018). Multivariate time series classification with WEASEL+MUSE. 3rd ECML/PKDD Workshop on AALTD.\n",
    "\n",
    "\\[8\\] Middlehurst, M., Schäfer, P., & Bagnall, A. (2023). Bake off redux. COMING SOON TO AN ARXIV NEAR YOU!."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}