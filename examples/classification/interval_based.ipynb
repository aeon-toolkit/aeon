{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interval based time series classification in sktime\n",
    "\n",
    "Interval based approaches look at phase dependant intervals of the full series,\n",
    "calculating summary statistics from selected subseries to be used in classification.\n",
    "They follow the ensemble model of random forest: each base classifier is a form of\n",
    "decision tree. Diversification is achieved by randomly sampling intervals\n",
    "\n",
    "<img src=\"./img/ensemble.png\" width=\"700\" alt=\"ensemble.\">\n",
    "\n",
    "Currently, there are five univariate interval based approaches are implemented in\n",
    "sktime. Time Series Forest (TSF) \\[1\\], the Random Interval Spectral Ensemble (RISE)\n",
    "\\[2\\], Supervised Time Series Forest (STSF) \\[3\\], the Canonical Interval Forest\n",
    "(CIF) \\[4\\]\n",
    " and the Diverse Representation Canonical Interval Forest (DrCIF) [5]. Both CIF and\n",
    " DrCIF have multivariate capabilities.\n",
    "\n",
    "In this notebook, we will demonstrate how to use these classifiers on the ItalyPowerDemand and BasicMotions datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:32:05.919120Z",
     "iopub.status.busy": "2020-12-19T14:32:05.918629Z",
     "iopub.status.idle": "2020-12-19T14:32:06.041420Z",
     "shell.execute_reply": "2020-12-19T14:32:06.040742Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (634118166.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[2], line 14\u001B[1;36m\u001B[0m\n\u001B[1;33m    return_X_y=True,\u001B[0m\n\u001B[1;37m              ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sktime.classification.interval_based import (\n",
    "    CanonicalIntervalForest,\n",
    "    DrCIF,\n",
    "    RandomIntervalSpectralEnsemble,\n",
    "    SupervisedTimeSeriesForest,\n",
    "    TimeSeriesForestClassifier,\n",
    ")\n",
    "from sktime.datasets import load_basic_motions, load_italy_power_demand\n",
    "\n",
    "X_test, y_test = load_italy_power_demand(split=\"test\")\n",
    "X_train, y_train = load_italy_power_demand(split=\"train\")\n",
    "X_test = X_test[:50]\n",
    "y_test = y_test[:50]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "X_train_mv, y_train_mv = load_basic_motions(split=\"train\")\n",
    "X_test_mv, y_test_mv = load_basic_motions(split=\"test\")\n",
    "\n",
    "X_train_mv = X_train_mv[:50]\n",
    "y_train_mv = y_train_mv[:50]\n",
    "X_test_mv = X_test_mv[:50]\n",
    "y_test_mv = y_test_mv[:50]\n",
    "\n",
    "print(X_train_mv.shape, y_train_mv.shape, X_test_mv.shape, y_test_mv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Forest (TSF)\n",
    "\n",
    "TSF[1] is the simplest interval based tree based ensemble. For each tree,sqrt(series_length)\n",
    "intervals are selected with a random position and length. The same interval offsets are applied to all series. For each interval, three summary statistics (the mean, variance and slope) are extracted  and concatenated into a feature vector. This feature vector is used to build the tree, and features extracted from the same intervals are used to make predictions. The ensembles predictions are made using a majority vote of all trees. The TSF base classifier is a modified decision tree classifier referred to as a time series tree, which considers all attributes at each node and uses a metric called margin gain to break ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:32:06.045197Z",
     "iopub.status.busy": "2020-12-19T14:32:06.044696Z",
     "iopub.status.idle": "2020-12-19T14:32:06.460714Z",
     "shell.execute_reply": "2020-12-19T14:32:06.461260Z"
    }
   },
   "outputs": [],
   "source": [
    "tsf = TimeSeriesForestClassifier(n_estimators=50, random_state=47)\n",
    "tsf.fit(X_train, y_train)\n",
    "tsf_preds = tsf.predict(X_test)\n",
    "print(f\"TSF Accuracy: {metrics.accuracy_score(y_test, tsf_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Interval Spectral Ensemble (RISE)\n",
    "\n",
    "First developed for the HIVE-COTE ensemble, RISE [2] is an\n",
    "interval based tree ensemble that uses spectral features. Unlike TSF, RISE selects a single random interval for each base classifier. The periodogram and auto-regression function are calculated over each randomly selected interval, and these features are concatenated into a feature vector, from which a tree is built. RISE was primarily designed for use with audio problems, where spectral features are more likely to be discriminatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rise = RandomIntervalSpectralEnsemble(n_estimators=50, random_state=47)\n",
    "rise.fit(X_train, y_train)\n",
    "\n",
    "rise_preds = rise.predict(X_test)\n",
    "print(f\"RISE Accuracy: {metrics.accuracy_score(y_test, rise_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supervised Time Series Forest (STSF)\n",
    "\n",
    "STSF [3] is an interval based tree ensemble that includes a supervised method for\n",
    "extracting intervals. Intervals are found and extracted for a periodogram and first order differences representation as well as the base series. STSF introduces bagging for each tree and extracts seven simple summary statistics from each interval. For each tree, an initial split point for the series is randomly selected. For both of these splits, the remaining subseries is cut in half, and the half with the higher Fisher score is retained as an interval. This process is then run recursively using higher scored intervals until the series is smaller than a threshold. This is repeated for each of the seven summary statistic features, with the extracted statistic being used to calculate the Fisher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsf = SupervisedTimeSeriesForest(n_estimators=50, random_state=47)\n",
    "stsf.fit(X_train, y_train)\n",
    "\n",
    "stsf_preds = stsf.predict(X_test)\n",
    "print(\"STSF Accuracy: \" + str(metrics.accuracy_score(y_test, stsf_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Canonical Interval Forest (CIF)\n",
    "\n",
    "CIF [4] is another extension of TSF, that improves\n",
    "accuracy by integrating more informative features and by increasing diversity. Like\n",
    "other interval approaches, CIF is an ensemble of decision tree classifiers built on\n",
    "features extracted from phase dependent intervals. Alongside the mean, standard\n",
    "deviation and slope, CIF also extracts the catch22 features [5].  Intervals remain\n",
    "randomly generrated, with each tree selecting  $\\sqrt{m}\\sqrt{d}$ intervals. To add additional diversity to the ensemble, $a$ attributes out of the pool of $25$ are randomly selected for each tree.\n",
    "    The extracted features are concatenated into a $k \\cdot a$ length vector for each data series and used to build the tree. For multivariate data, CIF randomly selects the dimension used for each interval.\n",
    "\n",
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:32:06.471294Z",
     "iopub.status.busy": "2020-12-19T14:32:06.467536Z",
     "iopub.status.idle": "2020-12-19T14:32:10.775056Z",
     "shell.execute_reply": "2020-12-19T14:32:10.775964Z"
    }
   },
   "outputs": [],
   "source": [
    "cif = CanonicalIntervalForest(n_estimators=50, att_subsample_size=8, random_state=47)\n",
    "cif.fit(X_train, y_train)\n",
    "\n",
    "cif_preds = cif.predict(X_test)\n",
    "print(\"CIF Accuracy on Italy: \" + str(metrics.accuracy_score(y_test, cif_preds)))\n",
    "cif_m = CanonicalIntervalForest(n_estimators=50, att_subsample_size=8, random_state=47)\n",
    "cif_m.fit(X_train_mv, y_train_mv)\n",
    "\n",
    "cif_m_preds = cif_m.predict(X_test_mv)\n",
    "print(\"CIF Accuracy on Motion: \" + str(metrics.accuracy_score(y_test_mv, cif_m_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Diverse Representation Canonical Interval Forest (DrCIF)\n",
    "\n",
    "(DrCIF) [6] incorporates two new series representations: the\n",
    "periodograms (also used by RISE and STSF) and first order differences (also used by STSF). For each of the three representations, $(4 + \\sqrt{r}\\sqrt{d})/3$ phase dependent intervals are randomly selected and concatenated into a feature vector, where $r$ is the length of the series for a representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drcif = DrCIF(n_estimators=5, att_subsample_size=10, random_state=47)\n",
    "drcif.fit(X_train, y_train)\n",
    "\n",
    "drcif_preds = drcif.predict(X_test)\n",
    "print(\"DrCIF Accuracy: \" + str(metrics.accuracy_score(y_test, drcif_preds)))\n",
    "drcif.fit(X_train_mv, y_train_mv)\n",
    "drcif_preds = drcif.predict(X_test_mv)\n",
    "print(\"DrCIF Accuracy: \" + str(metrics.accuracy_score(y_test_mv, drcif_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### References:\n",
    "\n",
    "\\[1\\] Deng, H., Runger, G., Tuv, E., & Vladimir, M. (2013). A time series forest for classification and feature extraction. Information Sciences, 239, 142-153.\n",
    "\n",
    "\\[2\\] Flynn, M., Large, J., & Bagnall, T. (2019). The contract random interval spectral ensemble (c-RISE): the effect of contracting a classifier on accuracy. In International Conference on Hybrid Artificial Intelligence Systems (pp. 381-392). Springer, Cham.\n",
    "\n",
    "\\[3\\] Cabello, N., Naghizade, E., Qi, J., & Kulik, L. (2020). Fast and Accurate Time Series Classification Through Supervised Interval Search. In IEEE International Conference on Data Mining.\n",
    "\n",
    "\\[4\\] Middlehurst, M., Large, J., & Bagnall, A. (2020). The Canonical Interval Forest (CIF) Classifier for Time Series Classification. arXiv preprint arXiv:2008.09172.\n",
    "\n",
    "\\[5\\] Lubba, C. H., Sethi, S. S., Knaute, P., Schultz, S. R., Fulcher, B. D., & Jones, N. S. (2019). catch22: CAnonical Time-series CHaracteristics. Data Mining and Knowledge Discovery, 33(6), 1821-1852.\n",
    "\n",
    "\\[6\\] Middlehurst M, Large J, Flynn M, Lines J, Bostrom A, Bagnall A (2021) HIVE-COTE 2.0: a new meta ensemble for time series classification. Machine Learning 110:3211–3243"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
