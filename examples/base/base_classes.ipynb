{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Overview of the base class structure\n",
    "\n",
    "`aeon` uses a core inheritance hierarchy of classes across the toolkit, with specialised sub classes in each module. The basic class hierarchy is shown in the following diagram.\n",
    "\n",
    "<img src=\"img/aeon_uml_simple.drawio.png\" alt=\"Basic class hierarchy\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Scikit-learn `BaseEstimator` and aeon `BaseAeonEstimator`\n",
    "\n",
    "To make sense of this, we break it down from the top.\n",
    "Everything inherits from sklearn `BaseEstimator`, which mainly handles the mechanisms for getting and setting parameters using the `set_params` and `get_params` methods. These methods are used when the estimators interact with other classes such as [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), and is also used in aeon's `ComposableEstimatorMixin`, which we'll talk about later.\n",
    "\n",
    "Then we have aeon's `BaseAeonEstimator` class. This class handles the following for all aeon's estimator:\n",
    "- management of tags, setting, getting, interaction with sklearn's tags, etc.\n",
    "- cloning and resetting of the estimator\n",
    "- creation of test instances using test parameters specified by each estimators. For example, this is used to define fast-running estimator (e.g. a forest classifier with only 2 trees) for the CI/CD pipelines.\n",
    "\n",
    "#### A word on aeon's estimator tag system\n",
    "Tags in aeon are used for various purposes, to display estimators capabilities in the documentations, to use specific tests based on each estimator's capabilities. You can check [all existing tags in aeon](https://github.com/aeon-toolkit/aeon/blob/main/aeon/utils/tags/_tags.py) and the [developer documentation on the testing framework](https://www.aeon-toolkit.org/en/stable/developer_guide/testing.html#) to know more about how we use tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## `BaseCollectionEstimator` and `BaseSeriesEstimator`\n",
    "\n",
    "We distinguish between two types of inputs for aeon estimators, series and collections:\n",
    "- Series represent single time series as a 2D format `(n_channels, n_timepoints)`, some estimators can also use 1D format as `(n_timepoints)` when they don't support multivariate series. Series estimators also have an `axis` parameter, which allow the input shape to be transposed such as the 2D format becomes `(n_timepoints, n_channels)` instead.\n",
    "- Collections represent an ensemble of time series as a 3D format `(n_samples, n_channels, n_timepoints)`. Again, this can sometime be represented as a 2D format such as `(n_samples, n_timepoints)` for univariate estimators. Preferably, this should be avoided to clear any confusion on the meaning of axes and the possible confusion with with 2D single series. More information on this problem can be found in [this notebook](series_estimator.ipynb).\n",
    "\n",
    "For example, if we go back to the base class schema `BaseClassifier` inherit from `BaseCollectionEstimator`. This means that during `fit` and `predict`, all estimators inheriting from `BaseClassifier` will take time series collection as inputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection base estimators\n",
    "\n",
    "The `BaseCollectionEstimator` defines methods to check the shape of the input, extract metadata (e.g. whether the collection is multivariate) and check compatibility of the input against tags of the estimators. For example, when you do the following : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data seen by instance of TemporalDictionaryEnsemble has unequal length series, but TemporalDictionaryEnsemble cannot handle these characteristics. \n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.dictionary_based import TemporalDictionaryEnsemble\n",
    "from aeon.testing.data_generation import make_example_3d_numpy_list\n",
    "\n",
    "# TDE does not support unequal length collections\n",
    "X_unequal, y_unequal = make_example_3d_numpy_list()\n",
    "try:\n",
    "    TemporalDictionaryEnsemble().fit(X_unequal, y_unequal)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens here is that `TemporalDictionaryEnsemble` inherit from `BaseClassifier`, which itself inherit from `BaseCollectionEstimator`. During `fit` and `predict`, `BaseClassifier` calls `_preprocess_collection`, a function defined in `BaseCollectionEstimator`. This function extracts the input metadata (whether it is multivariate, of unequal lengths etc.) and compare it against `TemporalDictionaryEnsemble` tags. These states that the estimator does not support unequal lengths collections, and hence an exception is raised. \n",
    "\n",
    "### `BaseClassifier` (aeon.classification)\n",
    "\n",
    "This is the base class for all classifiers. It uses the standard `fit`, `predict` and `predict_proba` structure from `sklearn`. `fit` and `predict` call the abstract methods `_fit` and `_predict` which are implemented in the subclass to define the classification algorithm. All of the common format checking and conversion are done in final functions such as `fit`, `predict` and are made before calling the abstract methods `_fit` and `_predict`. \n",
    "\n",
    "When implementing a new classifier inheriting from `BaseClassifier`, you thus only have to implement the `__init__`, `_fit` and `_predict` methods that handle the classification logic of the classifier. Also, you will need to set the correct tags to allow the check and conversion to be done for you. Note that each base class also define some attributes that are commonly used in the estimators, for example `BaseClassifier` exposes `classes_`, `n_classes_`, `_class_dictionary` that we can use in our new classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 0 1 0 1 0]\n",
      "[0, 1, 1, 0, 0, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "from aeon.classification import BaseClassifier\n",
    "from aeon.testing.data_generation import (\n",
    "    make_example_3d_numpy,\n",
    "    make_example_dataframe_list,\n",
    ")\n",
    "\n",
    "\n",
    "class RandomClassifier(BaseClassifier):\n",
    "    \"\"\"A dummy classifier returning random predictions.\"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multivariate\": True,  # allow multivariate collections\n",
    "        \"capability:unequal_length\": True,  # allow multivariate collections\n",
    "        \"X_inner_type\": [\"np-list\", \"numpy3D\"],  # Specify data format used internally\n",
    "    }\n",
    "\n",
    "    def __init__(self, random_state: int = 42):\n",
    "        self.random_state = random_state\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        self.rng = default_rng(self.random_state)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        # generate a random int between 0 and n_classes-1 and use _class_dictionary\n",
    "        # to convert it to class label\n",
    "        return [\n",
    "            self._class_dictionary[i]\n",
    "            for i in self.rng.integers(low=0, high=self.n_classes_, size=len(X))\n",
    "        ]\n",
    "\n",
    "\n",
    "X, y = make_example_3d_numpy(n_channels=2)\n",
    "print(RandomClassifier().fit_predict(X, y))\n",
    "X, y = make_example_dataframe_list()\n",
    "print(RandomClassifier().fit(X, y).predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### `BaseRegressor`, `BaseClusterer` and `BaseCollectionAnomalyDetector` \n",
    "These base classes are mostly similar to `BaseClassifier` in how they use the checks and conversion operations from `BaseCollectionEstimator`.\n",
    "\n",
    "- `BaseRegressor` also defines a `fit`and `predict` method and requires `_fit`and `_predict` methods to be implemented by child classes. The difference is that it has no `predict_proba` method. The tests on `y` are also different, as we can have floats has values for `y`.\n",
    "\n",
    "- `BaseClusterer` also has `fit` and `predict`, but does not take input `y` as child classes can be unsupervised estimators. It does include `predict_proba`.\n",
    "\n",
    "- `BaseCollectionAnomalyDetector` also has `fit` and `predict`, but does not take input `y` as child classes can be unsupervised estimators.\n",
    "\n",
    "\n",
    "### `BaseCollectionTransformer` \n",
    "\n",
    "Rather than `fit` and`predict`, the `BaseCollectionTransformer` implements `fit`, `transform` and `fit_transform` methods. It will require child classes to define `_fit`and `_transform` methods. The output of the transform method is not fixed and should be specified with the `output_data_type`.\n",
    "\n",
    "For example, if the output is another collection of time series (e.g. after using `SAX`), then `output_data_type` must take the `Collection` value (note that this is the default value for all `BaseCollectionTransformer` child classes). If the output is not time series anymore, but rather a 2D array of  features extracted from each input time series, such as in `Rocket` or `RandomShapeletTransform`, then the `output_data_type` must take the `Tabular`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Series base estimators\n",
    "### `BaseForecaster`\n",
    "### `BaseSegmenter`\n",
    "### `BaseSeriesTransformer`\n",
    "### `BaseSeriesAnomalyDetector`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
