{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Overview of the base class structure\n",
    "\n",
    "`aeon` uses a core inheritance hierarchy of classes across the toolkit, with specialised sub classes in each module. The basic class hierarchy is shown in the following diagram.\n",
    "\n",
    "<img src=\"img/aeon_uml_simple.drawio.png\" alt=\"Basic class hierarchy\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Scikit-learn `BaseEstimator` and aeon `BaseAeonEstimator`\n",
    "\n",
    "To make sense of this, we break it down from the top.\n",
    "Everything inherits from sklearn `BaseEstimator`, which mainly handles the mechanisms for getting and setting parameters using the `set_params` and `get_params` methods. These methods are used when the estimators interact with other classes such as [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), and is also used in aeon's `ComposableEstimatorMixin`, which we'll talk about later.\n",
    "\n",
    "Then we have aeon's `BaseAeonEstimator` class. This class handles the following for all aeon's estimator:\n",
    "- management of tags, setting, getting, interaction with sklearn's tags, etc.\n",
    "- cloning and resetting of the estimator\n",
    "- creation of test instances using test parameters specified by each estimators. For example, this is used to define fast-running estimator (e.g. a forest classifier with only 2 trees) for the CI/CD pipelines.\n",
    "\n",
    "#### A word on aeon's estimator tag system\n",
    "Tags in aeon are used for various purposes, to display estimators capabilities in the documentations, to use specific tests based on each estimator's capabilities. You can check [all existing tags in aeon](https://github.com/aeon-toolkit/aeon/blob/main/aeon/utils/tags/_tags.py) and the [developer documentation on the testing framework](https://www.aeon-toolkit.org/en/stable/developer_guide/testing.html#) to know more about how we use tags.\n",
    "\n",
    "One of the main use of tags is input or output formatting and checking made by base classes. Some important tags in this regard are :\n",
    "- `X_inner_type` tag, used to specify the expected type of the input data (Arrays, DataFrames, Lists) used in the implementation. For example, this allows estimator to take both numpy arrays and pandas DataFrames as input, while the implementation uses numpy arrays only. \n",
    "- `output_data_type` tag, used to specify the expected type of the output data (e.g. tabular, series, collections). This is mostly used by transformations estimators.\n",
    "- `capability:multivariate` tag, which indicates whether the estimator can handle multivariate time series data.\n",
    "- `capability:unequal_length` tag, which indicates whether the estimator can handle collection of unequal length time series data.\n",
    "- `capability:multithreading` tag, which indicates whether the estimator can handle multithreading for parallel processing.\n",
    "\n",
    "We will give some examples using these tags in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## `BaseCollectionEstimator` and `BaseSeriesEstimator`\n",
    "\n",
    "We distinguish between two types of inputs for aeon estimators, series and collections:\n",
    "- Series represent single time series as a 2D format `(n_channels, n_timepoints)`, some estimators can also use 1D format as `(n_timepoints)` when they don't support multivariate series. Series estimators also have an `axis` parameter, which allow the input shape to be transposed such as the 2D format becomes `(n_timepoints, n_channels)` instead.\n",
    "- Collections represent an ensemble of time series as a 3D format `(n_samples, n_channels, n_timepoints)`. Again, this can sometime be represented as a 2D format such as `(n_samples, n_timepoints)` for univariate estimators. Preferably, this should be avoided to clear any confusion on the meaning of axes and the possible confusion with with 2D single series. More information on this problem can be found in [this notebook](series_estimator.ipynb).\n",
    "\n",
    "For example, if we go back to the base class schema `BaseClassifier` inherit from `BaseCollectionEstimator`. This means that during `fit` and `predict`, all estimators inheriting from `BaseClassifier` will take time series collection as inputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection base estimators\n",
    "\n",
    "The `BaseCollectionEstimator` defines methods to check the shape of the input, extract metadata (e.g. whether the collection is multivariate) and check compatibility of the input against tags of the estimators. For example, when you do the following : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data seen by instance of TemporalDictionaryEnsemble has unequal length series, but TemporalDictionaryEnsemble cannot handle these characteristics. \n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.dictionary_based import TemporalDictionaryEnsemble\n",
    "from aeon.testing.data_generation import make_example_3d_numpy_list\n",
    "\n",
    "# TDE does not support unequal length collections\n",
    "# as it sets \"capability: unequal_length\":False\n",
    "X_unequal, y_unequal = make_example_3d_numpy_list()\n",
    "try:\n",
    "    TemporalDictionaryEnsemble().fit(X_unequal, y_unequal)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens here is that `TemporalDictionaryEnsemble` inherits from `BaseClassifier`, which itself inherits from `BaseCollectionEstimator`. During `fit` and `predict`, `BaseClassifier` calls `_preprocess_collection`, a function defined in `BaseCollectionEstimator`. This function extracts the input metadata (whether it is multivariate, of unequal lengths etc.) and compare it against `TemporalDictionaryEnsemble` tags. These state that the estimator does not support unequal lengths collections, and hence an exception is raised. \n",
    "\n",
    "### `BaseClassifier` (aeon.classification)\n",
    "\n",
    "This is the base class for all classifiers. It uses the standard `fit`, `predict` and `predict_proba` structure from `sklearn`. `fit` and `predict` call the abstract methods `_fit` and `_predict` which are implemented in the subclass to define the classification algorithm. All of the common format checking and conversion are done in final functions such as `fit`, `predict` and are made before calling the abstract methods `_fit` and `_predict`. \n",
    "\n",
    "When implementing a new classifier inheriting from `BaseClassifier`, you thus only have to implement the `__init__`, `_fit` and `_predict` methods that handle the classification logic of the classifier. You will also need to set the correct tags to allow the check and conversion to be done for you. Note that each base class also defines some attributes that are commonly used in the estimators, for example `BaseClassifier` exposes `classes_`, `n_classes_`, `_class_dictionary` that we can use in our new classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 0 1 0 1 0]\n",
      "[0, 1, 1, 0, 0, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "from aeon.classification import BaseClassifier\n",
    "from aeon.testing.data_generation import (\n",
    "    make_example_3d_numpy,\n",
    "    make_example_dataframe_list,\n",
    ")\n",
    "\n",
    "\n",
    "class RandomClassifier(BaseClassifier):\n",
    "    \"\"\"A dummy classifier returning random predictions.\"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multivariate\": True,  # allow multivariate collections\n",
    "        \"capability:unequal_length\": True,  # allow multivariate collections\n",
    "        \"X_inner_type\": [\"np-list\", \"numpy3D\"],  # Specify data format used internally\n",
    "    }\n",
    "\n",
    "    def __init__(self, random_state: int = 42):\n",
    "        self.random_state = random_state\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        self.rng = default_rng(self.random_state)\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X):\n",
    "        # generate a random int between 0 and n_classes-1 and use _class_dictionary\n",
    "        # to convert it to class label\n",
    "        return [\n",
    "            self._class_dictionary[i]\n",
    "            for i in self.rng.integers(low=0, high=self.n_classes_, size=len(X))\n",
    "        ]\n",
    "\n",
    "\n",
    "X, y = make_example_3d_numpy(n_channels=2)\n",
    "print(RandomClassifier().fit_predict(X, y))\n",
    "X, y = make_example_dataframe_list()\n",
    "print(RandomClassifier().fit(X, y).predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Further reading**\n",
    "- the [classification example notebook](../classification/classification.ipynb).\n",
    "\n",
    "### `BaseRegressor`, `BaseClusterer` and `BaseCollectionAnomalyDetector` \n",
    "These base classes are mostly similar to `BaseClassifier` in how they use the checks and conversion operations from `BaseCollectionEstimator`.\n",
    "\n",
    "- `BaseRegressor` also defines a `fit`and `predict` method and requires `_fit`and `_predict` methods to be implemented by child classes. The difference is that it has no `predict_proba` method yet, as we still need to decide how to model probabilistic regression for time series. The tests on `y` are also different, as we can have floats has values for `y`.\n",
    "\n",
    "- `BaseClusterer` also has `fit` and `predict`, but does not take input `y` as child classes can be unsupervised estimators. It does include `predict_proba`.\n",
    "\n",
    "- `BaseCollectionAnomalyDetector` also has `fit` and `predict`, but does not take input `y` as child classes can be unsupervised estimators.\n",
    "\n",
    "**Further reading**\n",
    "- the [regression example notebook](../regression/regression.ipynb).\n",
    "- the [clustering example notebook](../clustering/clustering.ipynb).\n",
    "- the [anomaly detection example notebook](../anomaly_detection/anomaly_detection.ipynb).\n",
    "\n",
    "### `BaseCollectionTransformer` \n",
    "\n",
    "Rather than `fit` and`predict`, the `BaseCollectionTransformer` implements `fit`, `transform` and `fit_transform` methods, which are required since this base class also inherits the `BaseTransformer` class. It will require child classes to define `_fit`and `_transform` methods. The output of the transform method is not fixed and should be specified with the `output_data_type`.\n",
    "\n",
    "For example, if the output is another collection of time series (e.g. after using `SAX`), then `output_data_type` must take the `Collection` value (note that this is the default value for all `BaseCollectionTransformer` child classes). If the output is not time series anymore, but rather a 2D array of  features extracted from each input time series, such as in `Rocket` or `RandomShapeletTransform`, then the `output_data_type` must take the `Tabular`.\n",
    "\n",
    "**Further reading**\n",
    "- the [transformation notebook](../transformations/transformations.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Series base estimators\n",
    "\n",
    "Series estimators are similar to collection estimators, but they take single time series as input. They inherit from `BaseSeriesEstimator`, which perform similar operations to `BaseCollectionEstimator`, such as input checks and conversions, but for single time series.\n",
    "\n",
    "One important difference is the use of the `axis` parameter, which allows each estimator to define whether it works with the `(n_channels, n_timepoints)` or the `(n_timepoints, n_channels)` 2D format. We need to have the axis parameter, because for 2D series, there is no way to infer whether an input 2D time series is in the `(n_channels, n_timepoints)` or `(n_timepoints, n_channels)` format. \n",
    "\n",
    "To understand its uses, we need to distinguish between the `axis` parameter set during initialisation of the estimator, and the `axis` parameter used in the `fit`, `predict` and other methods:\n",
    "- `axis` given during initialisation is used to define the internal format used by the estimator,\n",
    "- `axis` given when call functions is used to transpose the input time series if needed, to match the format internally used by the estimator.\n",
    "\n",
    "Note that the axis value represent the dimension in which the number of timepoints is stored, so `axis=0` means that the timepoints are stored in the first dimension, and `axis=1` means that the timepoints are stored in the second dimension (i.e. `(n_channels, n_timepoints)`).\n",
    "\n",
    "**Further reading**\n",
    "- the [series estimators notebook](series_estimator.ipynb).\n",
    "\n",
    "### `BaseSeriesTransformer`\n",
    "\n",
    "Let's take the example of `BaseSeriesTransformer`, which is the base class for all series transformers. It implements the `fit`, `transform` and `fit_transform` methods, and requires child classes to implement `_fit` and `_transform`. Let use demonstrate the use of the axis parameter with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "(2, 10)\n",
      "(2, 5)\n",
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "from aeon.testing.data_generation import make_example_dataframe_series\n",
    "from aeon.transformations.series import BaseSeriesTransformer\n",
    "\n",
    "\n",
    "class DummySeriesTransformer(BaseSeriesTransformer):\n",
    "    \"\"\"A dummy series transformer that keeps every second timepoint.\"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multivariate\": True,  # allow multivariate series\n",
    "        \"X_inner_type\": \"pd.DataFrame\",  # Specify data format used internally\n",
    "        \"fit_is_empty\": True,  # we don't need to define _fit\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(axis=1)  # Set axis to 1 for (n_channels, n_timepoints) format\n",
    "\n",
    "    def _transform(self, X, y=None):\n",
    "        print(X.shape)\n",
    "        X = X.iloc[:, ::2]  # Example transformation: keep every second timepoint\n",
    "        print(X.shape)\n",
    "        return X\n",
    "\n",
    "\n",
    "X = make_example_dataframe_series(n_channels=2, n_timepoints=10).T\n",
    "print(X.shape)  # Is (n_timepoints, n_channels), which is axis=0\n",
    "print(DummySeriesTransformer().fit_transform(X, axis=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that `X` starts of shape `(n_timepoints, n_channels)`, which is the default format for the input time series. \n",
    "\n",
    "The `DummySeriesTransformer` is initialised with `axis=1`, meaning that internally, when calling `fit` and `transform`, the input is converted to `(n_channels, n_timepoints)` format before being passed to the `_fit` and `_transform` functions. The output is then converted back to the original format `(n_timepoints, n_channels)` before returning it.\n",
    "\n",
    "Note that as we specified pd.DataFrame as the `X_inner_type` in the tags, if the input is not a DataFrame, the estimator will convert it to a DataFrame before applying the transformation. This allows you to define and use a single input shape and type in the function you implement, while still allowing the estimator to handle different input formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "(1, 5)\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "from aeon.testing.data_generation import make_example_2d_numpy_series\n",
    "\n",
    "X = make_example_2d_numpy_series(n_channels=1, n_timepoints=10)\n",
    "transformer = DummySeriesTransformer()\n",
    "print(transformer.fit_transform(X, axis=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BaseForecaster`\n",
    "\n",
    "The `BaseForecaster` class inherits from `BaseSeriesEstimator` which provides the checks and conversion functions for single time series inputs. Forecasters predict future values of a time series `horizon` steps ahead. The `horizon` parameter is defined during initialization to specify how many steps ahead the forecaster should predict. The main methods are :\n",
    "\n",
    "- `fit(y, exog=None)`: Trains the forecaster on input data\n",
    "- `predict(y, exog=None)`: Makes predictions on new data\n",
    "- `forecast(y, exog=None)`: Combines fit and predict into one operation\n",
    "\n",
    "For child classes, the `_fit` and `_predict` methods must be implemented to define the forecasting logic.\n",
    "\n",
    "It also provides two main forecasting strategies:\n",
    "- `direct_forecast()`: Makes predictions by training separate models for each future step.  See [the direct forecasting notebook](../forecasting/direct.ipynb) for more information on this strategy.\n",
    "\n",
    "- `iterative_forecast()`: Makes predictions recursively using a single trained model. See [the itreative forecasting notebook](../forecasting/iterative.ipynb) for more information on this strategy.\n",
    "\n",
    "\n",
    "**Further reading**\n",
    "- the [forecasting example notebook](../forecasting/forecasting.ipynb).\n",
    "\n",
    "### `BaseSeriesAnomalyDetector` and  `BaseSegmenter`\n",
    "\n",
    "The `BaseSeriesAnomalyDetector` and the  `BaseSegmenter` base classes both implements the `fit`, `predict` but only requires child classes to implement the `_predict`, as most anomaly detector and segmenters are unsupervised estimators. Both also inherit from `BaseSeriesEstimator`, which provides the checking and conversion functions we have seen before\n",
    "\n",
    "**Further reading**\n",
    "- the [anomaly detection example notebook](../anomaly_detection/anomaly_detection.ipynb).\n",
    "- the [segmentation example notebook](../segmentation/segmentation.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon_dev_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
