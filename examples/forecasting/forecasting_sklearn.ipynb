{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and forecasting with aeon\n",
    "\n",
    "This notebook describes a built in way of forecasting using regression that\n",
    "encapsulates the whole process into a forecaster.\n",
    "\n",
    "From an interface perspective, forecasting through regression can be formulated as\n",
    "\"reduction\". There are dangers in a simplistic approach to forecasting via regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.641893Z",
     "iopub.status.busy": "2021-04-10T16:07:06.618023Z",
     "iopub.status.idle": "2021-04-10T16:07:06.787235Z",
     "shell.execute_reply": "2021-04-10T16:07:06.787715Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'. 'matplotlib' is a soft dependency and not included in the base aeon installation. Please run: `pip install matplotlib` to install the matplotlib package. To install all soft dependencies, run: `pip install aeon[all_extras]`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32mC:\\Code\\scikit-time\\aeon\\utils\\validation\\_dependencies.py:118\u001B[0m, in \u001B[0;36m_check_soft_dependencies\u001B[1;34m(package_import_alias, severity, obj, suppress_import_stdout, *packages)\u001B[0m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m         pkg_ref \u001B[38;5;241m=\u001B[39m \u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpackage_import_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;66;03m# if package cannot be imported, make the user aware of installation requirement\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:984\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m y \u001B[38;5;241m=\u001B[39m load_airline()\n\u001B[0;32m      7\u001B[0m y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(y)\n\u001B[1;32m----> 8\u001B[0m \u001B[43mplot_series\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my_train\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my_test\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m;\n",
      "File \u001B[1;32mC:\\Code\\scikit-time\\aeon\\utils\\plotting.py:63\u001B[0m, in \u001B[0;36mplot_series\u001B[1;34m(labels, markers, colors, title, x_label, y_label, ax, pred_interval, *series)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_series\u001B[39m(\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;241m*\u001B[39mseries,\n\u001B[0;32m     23\u001B[0m     labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m     pred_interval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     31\u001B[0m ):\n\u001B[0;32m     32\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Plot one or more time series.\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;124;03m    >>> fig, ax = plot_series(y)  # doctest: +SKIP\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 63\u001B[0m     \u001B[43m_check_soft_dependencies\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmatplotlib\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseaborn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Code\\scikit-time\\aeon\\utils\\validation\\_dependencies.py:140\u001B[0m, in \u001B[0;36m_check_soft_dependencies\u001B[1;34m(package_import_alias, severity, obj, suppress_import_stdout, *packages)\u001B[0m\n\u001B[0;32m    130\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    131\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires package \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to be present \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    132\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min the python environment, but \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m was not found. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    137\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maeon[all_extras]`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    138\u001B[0m     )\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m severity \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m severity \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarning\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    142\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'. 'matplotlib' is a soft dependency and not included in the base aeon installation. Please run: `pip install matplotlib` to install the matplotlib package. To install all soft dependencies, run: `pip install aeon[all_extras]`"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aeon.datasets import load_airline\n",
    "from aeon.forecasting.model_selection import temporal_train_test_split\n",
    "from aeon.utils.plotting import plot_series\n",
    "\n",
    "y = load_airline()\n",
    "y_train, y_test = train_test_split(y)\n",
    "plot_series(y_train.sort_index(), y_test.sort_index(), labels=[\"y_train\", \"y_test\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to leakage: The data you are using to train a machine learning algorithm happens to have the information you are trying to predict.\n",
    "\n",
    "But `train_test_split(y, shuffle=False)` works, which is what `temporal_train_test_split(y)` does in `aeon`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.861616Z",
     "iopub.status.busy": "2021-04-10T16:07:06.861025Z",
     "iopub.status.idle": "2021-04-10T16:07:07.016695Z",
     "shell.execute_reply": "2021-04-10T16:07:07.017191Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train, y_test = temporal_train_test_split(y)\n",
    "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitfall 2: obscure data manipulations, brittle boilerplate code to apply regressors\n",
    "\n",
    "It is common practice to apply supervised regressors after transforming the data for forecasting, through lagging - for example, in auto-regressive reduction strategies.\n",
    "\n",
    "Two important pitfalls appear right at the start:\n",
    "\n",
    "* a lot of boilerplate code has to be written to transform the data to make it ready for fitting - this is highly error prone\n",
    "* there are a number of implicit hyper-parameters here, such as window and lag size. If done without caution, these are not explicit or tracked in the experiment, which can lead to \"p-value hacking\".\n",
    "\n",
    "Below is an example of such boilerplate code to demonstrate this. The code is closely modelled on the R code used in the [M4 competition](https://github.com/Mcompetitions/M4-methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we want to predict 3 years ahead\n",
    "fh = np.arange(1, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.023411Z",
     "iopub.status.busy": "2021-04-10T16:07:07.022907Z",
     "iopub.status.idle": "2021-04-10T16:07:07.024499Z",
     "shell.execute_reply": "2021-04-10T16:07:07.024998Z"
    }
   },
   "outputs": [],
   "source": [
    "# slightly modified code from the M4 competition\n",
    "def split_into_train_test(data, in_num, fh):\n",
    "    \"\"\"\n",
    "    Splits the series into train and test sets.\n",
    "\n",
    "    Each step takes multiple points as inputs\n",
    "    :param data: an individual TS\n",
    "    :param fh: number of out of sample points\n",
    "    :param in_num: number of input points for the forecast\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train, test = data[:-fh], data[-(fh + in_num) :]\n",
    "    x_train, y_train = train[:-1], np.roll(train, -in_num)[:-in_num]\n",
    "    x_test, y_test = test[:-1], np.roll(test, -in_num)[:-in_num]\n",
    "    #     x_test, y_test = train[-in_num:], np.roll(test, -in_num)[:-in_num]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    # (N-NF samples, 1 time step, 1 feature)\n",
    "    x_train = np.reshape(x_train, (-1, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 1))\n",
    "    temp_test = np.roll(x_test, -1)\n",
    "    temp_train = np.roll(x_train, -1)\n",
    "    for _ in range(1, in_num):\n",
    "        x_train = np.concatenate((x_train[:-1], temp_train[:-1]), 1)\n",
    "        x_test = np.concatenate((x_test[:-1], temp_test[:-1]), 1)\n",
    "        temp_test = np.roll(temp_test, -1)[:-1]\n",
    "        temp_train = np.roll(temp_train, -1)[:-1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.028644Z",
     "iopub.status.busy": "2021-04-10T16:07:07.028108Z",
     "iopub.status.idle": "2021-04-10T16:07:07.029820Z",
     "shell.execute_reply": "2021-04-10T16:07:07.030335Z"
    }
   },
   "outputs": [],
   "source": [
    "# here we split the time index, rather than the actual values,\n",
    "# to show how we split the windows\n",
    "feature_window, target_window, _, _ = split_into_train_test(\n",
    "    np.arange(len(y)), 10, len(fh)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the prior data transformation, we can look at how we can split the training series into windows. Here we show the generated windows expressed as integer indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.033532Z",
     "iopub.status.busy": "2021-04-10T16:07:07.033064Z",
     "iopub.status.idle": "2021-04-10T16:07:07.035278Z",
     "shell.execute_reply": "2021-04-10T16:07:07.035836Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_window[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.038874Z",
     "iopub.status.busy": "2021-04-10T16:07:07.038346Z",
     "iopub.status.idle": "2021-04-10T16:07:07.040421Z",
     "shell.execute_reply": "2021-04-10T16:07:07.040933Z"
    }
   },
   "outputs": [],
   "source": [
    "target_window[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.044178Z",
     "iopub.status.busy": "2021-04-10T16:07:07.043592Z",
     "iopub.status.idle": "2021-04-10T16:07:07.046140Z",
     "shell.execute_reply": "2021-04-10T16:07:07.046641Z"
    }
   },
   "outputs": [],
   "source": [
    "# now we can split the actual values of the time series\n",
    "x_train, y_train, x_test, y_test = split_into_train_test(y.values, 10, len(fh))\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.083439Z",
     "iopub.status.busy": "2021-04-10T16:07:07.082648Z",
     "iopub.status.idle": "2021-04-10T16:07:07.167067Z",
     "shell.execute_reply": "2021-04-10T16:07:07.167558Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reiterate the potential pitfalls here:\n",
    "\n",
    "> The manual requires a lot of hand-written code which is often error-prone, not modular and not tuneable.\n",
    "\n",
    "These steps involve a number of implicit hyper-parameters:\n",
    "\n",
    "> * The way you slice the time series into windows (e.g. the window length);\n",
    "> * The way you generate forecasts (recursive strategy, direct strategy, other hybrid strategies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitfall 3: Given a fitted regression algorithm, how can we generate forecasts?\n",
    "\n",
    "The next important pitfall comes at the end:\n",
    "\n",
    "If making predictions along the \"manual route\" for supervised regressors, the supervised regressor's outputs have to be transformed back into forecasts. This is easily forgotten, and invites errors in forecasts and evaluation (see pitfall no.1) - especially, if one does not cleanly keep track of which data is known at what time, or how to invert the transformation made in fitting.\n",
    "\n",
    "A naive user might now proceed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.171836Z",
     "iopub.status.busy": "2021-04-10T16:07:07.171233Z",
     "iopub.status.idle": "2021-04-10T16:07:07.173018Z",
     "shell.execute_reply": "2021-04-10T16:07:07.173506Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# add back time index to y_test\n",
    "y_test = pd.Series(y_test, index=y.index[-len(fh) :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.180067Z",
     "iopub.status.busy": "2021-04-10T16:07:07.177212Z",
     "iopub.status.idle": "2021-04-10T16:07:07.186432Z",
     "shell.execute_reply": "2021-04-10T16:07:07.186959Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "\n",
    "mean_absolute_percentage_error(\n",
    "    y_test, pd.Series(y_pred, index=y_test.index), symmetric=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So easy, so wrong ... but what's the problem here? It's a bit subtle and not easy to spot:\n",
    "\n",
    "> We actually don't make a multi-step-ahead forecast up to the 36th step ahead. Instead, we make 36 single-step-ahead forecasts always using the most recent data. But that's a solution to a different learning task!\n",
    "\n",
    "To fix this problem, we could write some code to do this recursively as in the M4 competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.228733Z",
     "iopub.status.busy": "2021-04-10T16:07:07.219457Z",
     "iopub.status.idle": "2021-04-10T16:07:07.421143Z",
     "shell.execute_reply": "2021-04-10T16:07:07.421651Z"
    }
   },
   "outputs": [],
   "source": [
    "# slightly modified code from the M4 study\n",
    "predictions = []\n",
    "last_window = x_train[-1, :].reshape(1, -1)  # make it into 2d array\n",
    "\n",
    "last_prediction = model.predict(last_window)[0]  # take value from array\n",
    "\n",
    "for i in range(len(fh)):\n",
    "    # append prediction\n",
    "    predictions.append(last_prediction)\n",
    "\n",
    "    # update last window using previously predicted value\n",
    "    last_window[0] = np.roll(last_window[0], -1)\n",
    "    last_window[0, (len(last_window[0]) - 1)] = last_prediction\n",
    "\n",
    "    # predict next step ahead\n",
    "    last_prediction = model.predict(last_window)[0]\n",
    "\n",
    "y_pred_rec = pd.Series(predictions, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "\n",
    "mean_absolute_percentage_error(\n",
    "    y_test, pd.Series(y_pred_rec, index=y_test.index), symmetric=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize the potential pitfalls here:\n",
    "\n",
    "> Obtaining regressor predictions and converting them back into forecasts is non-trivial and error prone:\n",
    "> * some boilerplate code needs to be written, which just as in pitfall no.2 introduces potential for problems;\n",
    "> * It isn't exactly obvious that this boilerplate code had to be written in the first place, creating a subtle failure point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does `aeon` help avoid the above pitfalls?\n",
    "\n",
    "`aeon` mitigates the above pitfalls with:\n",
    "\n",
    "* Its unified interface for forecasters - any strategy to produce forecasts is a forecaster. Through the unified interface, forecasters are directly compatible with deployment and evaluation workflows appropriate for forecasters;\n",
    "* Its declarative specification interface that minimizes boilerplate code - it's minimized to the bare necessities to tell `aeon` which forecaster you want to build.\n",
    "\n",
    "Nevertheless, `aeon` aims to be flexible, and tries to avoid to railroad the user into specific methodological choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from aeon.forecasting.compose import make_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declarative forecaster specification - just two lines!\n",
    "regressor = KNeighborsRegressor(n_neighbors=1)\n",
    "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and that's it!\n",
    "\n",
    "Note that there is no `x_train` or other boilerplate artefacts, since construction of the lagged features and other boilerplate code are taken care of by the forecaster internally.\n",
    "\n",
    "For more details on the `aeon` composition interface, refer to Section 3 of the main forecasting tutorial."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "1a1494236c8ef7f8181df502ed65395fa49dc4c7792b0159c6c2a3cecbe5c345"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aeon-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
