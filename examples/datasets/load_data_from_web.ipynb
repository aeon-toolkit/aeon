{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Downloading and loading benchmarking datasets\n",
    "\n",
    "It is common to use standard collections of data to compare different estimators for\n",
    "classification, clustering, regression, forecasting, and anomaly detection. Some of\n",
    "these datasets are shipped with aeon in the datasets/data directory. However, the files\n",
    "are far too big to include them all. aeon provides tools to download these data to use\n",
    "in benchmarking experiments. Classification and regression data are stored in .ts\n",
    "format. Forecasting data are stored in the equivalent .tsf format. Anomaly detection\n",
    "datasets are stored in the TimeEval .csv format. See the\n",
    "[data loading notebook](data_loading.ipynb) for more info.\n",
    "\n",
    "Classification and regression are loaded into 3D numpy arrays of shape\n",
    "`(n_cases, n_channels, n_timepoints)` if equal length or a list of `[n_cases]` of 2D\n",
    "numpy if `n_timepoints` is different for different cases. Forecasting data are loaded\n",
    "into pd.DataFrame. Anomaly detection dataset are loaded into 2D numpy arrays of shape\n",
    "`(n_timepoints, n_channels)`. For more information on aeon data types see the\n",
    "[data structures notebook](data_structures.ipynb).\n",
    "\n",
    "Note that this notebook is dependent on external websites, so will not function if\n",
    "you are not online or the associated website is down. We use the following four\n",
    "functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from aeon.datasets import (\n",
    "    load_anomaly_detection,\n",
    "    load_classification,\n",
    "    load_forecasting,\n",
    "    load_regression,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:18.978527Z",
     "start_time": "2024-06-17T13:07:18.453465Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Series Classification Archive\n",
    "\n",
    "[UCR/TSML Time Series Classification Archive](https://timeseriesclassification.com)\n",
    "hosts the UCR univariate TSC archive [1], also available from [UCR](https://www.cs.ucr.edu/~eamonn/time_series_data_2018/) and\n",
    "the multivariate archive [2] (previously called the UEA archive, soon to change). We\n",
    "provide seven of these in the datasets/data directort: ACSF1, ArrowHead, BasicMotions,\n",
    "GunPoint, ItalyPowerDemand, JapaneseVowels and PLAID. The archive is much bigger. The\n",
    " last batch release was for 128 univariate [1] and 33 multivariate [2]. If you just\n",
    " want to download them all, please go to the [website](https://timeseriesclassification.com)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate length =  128\n",
      "Multivariate length =  30\n"
     ]
    }
   ],
   "source": [
    "from aeon.datasets.tsc_datasets import multivariate, univariate\n",
    "\n",
    "# This file also contains sub lists by type, e.g. unequal length\n",
    "print(\"Univariate length = \", len(univariate))\n",
    "print(\"Multivariate length = \", len(multivariate))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:18.985584Z",
     "start_time": "2024-06-17T13:07:18.980660Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A default train and test split is provided for this data. The file structure for a\n",
    "problem such as Chinatown is\n",
    "\n",
    "        <extract_path>/Chinatown/Chinatown_TRAIN.ts\n",
    "        <extract_path>/Chinatown/Chinatown_TEST.ts\n",
    "\n",
    "You can load these problems directly from TSC.com and load them into memory. These\n",
    "functions can return associated metadata in addition to the data. This usage combines\n",
    " the train and test splits and loads them into one `X` and one `y` array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X =  (363, 1, 24)\n",
      "First case =  [ 573.  375.  301.  212.   55.   34.   25.   33.  113.  143.  303.  615.\n",
      " 1226. 1281. 1221. 1081.  866. 1096. 1039.  975.  746.  581.  409.  182.]  has label =  1\n",
      "\n",
      "Meta data =  {'problemname': 'chinatown', 'timestamps': False, 'missing': False, 'univariate': True, 'equallength': True, 'classlabel': True, 'targetlabel': False, 'class_values': ['1', '2']}\n"
     ]
    }
   ],
   "source": [
    "X, y, meta = load_classification(\"Chinatown\", return_metadata=True)\n",
    "print(\"Shape of X = \", X.shape)\n",
    "print(\"First case = \", X[0][0], \" has label = \", y[0])\n",
    "print(\"\\nMeta data = \", meta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:19.007332Z",
     "start_time": "2024-06-17T13:07:18.987354Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you look in aeon/datasets you should see a directory called `local_data`\n",
    "containing the Chinatown datasets. All of the zips have `.ts` files. Some also have\n",
    "`.arff` and `.txt` files. File structure looks something like this:\n",
    "\n",
    "<img src=\"img/download2.png\" width=\"300\" alt=\"time series classification\">\n",
    "\n",
    "Within each folder are the data in text files formatted as .ts files (see the [data\n",
    "loading notebook](data_loading.ipynb) for file format description). They may also be\n",
    "available in .arff format and .txt format.\n",
    "\n",
    "<img src=\"img/download1.png\" width=\"600\" alt=\"time series classification\">\n",
    "\n",
    "If you load again with the same extract path it will not download again if the file is\n",
    "already there. If you want to store data somewhere else, you can specify a file path.\n",
    " Also, you can load the train and test separately. This code will download the data\n",
    " to Temp once, and load into separate train/test splits. The split argument is not\n",
    " case sensitive. Once downloaded, `load_classification` is a equivalent to a call to\n",
    " `load_from_tsfile`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Series (Extrinsic) Regression\n",
    "\n",
    "[The Monash Time Series Extrinsic Regression Archive]() [3] repo (called extrinsic to\n",
    " diffentiate if from sliding window based regression) currently contains 19\n",
    " regression problems in .ts format. One of these, Covid3Month, is in `datasets\\data`.\n",
    "  We have recently expanded this repo to include 63 problems in .ts format.\n",
    "  The usage of `load_regression` is identical to `load_classification`\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['AcousticContaminationMadrid',\n 'AluminiumConcentration',\n 'AppliancesEnergy',\n 'AustraliaRainfall',\n 'BIDMC32HR',\n 'BIDMC32RR',\n 'BIDMC32SpO2',\n 'BarCrawl6min',\n 'BeijingIntAirportPM25Quality',\n 'BeijingPM10Quality',\n 'BeijingPM25Quality',\n 'BenzeneConcentration',\n 'BinanceCoinSentiment',\n 'BitcoinSentiment',\n 'BoronConcentration',\n 'CalciumConcentration',\n 'CardanoSentiment',\n 'ChilledWaterPredictor',\n 'CopperConcentration',\n 'Covid19Andalusia',\n 'Covid3Month',\n 'DailyOilGasPrices',\n 'DailyTemperatureLatitude',\n 'DhakaHourlyAirQuality',\n 'ElectricMotorTemperature',\n 'ElectricityPredictor',\n 'EthereumSentiment',\n 'FloodModeling1',\n 'FloodModeling2',\n 'FloodModeling3',\n 'GasSensorArrayAcetone',\n 'GasSensorArrayEthanol',\n 'HotwaterPredictor',\n 'HouseholdPowerConsumption1',\n 'HouseholdPowerConsumption2',\n 'IEEEPPG',\n 'IronConcentration',\n 'LPGasMonitoringHomeActivity',\n 'LiveFuelMoistureContent',\n 'MadridPM10Quality',\n 'MagnesiumConcentration',\n 'ManganeseConcentration',\n 'MethaneMonitoringHomeActivity',\n 'MetroInterstateTrafficVolume',\n 'NaturalGasPricesSentiment',\n 'NewsHeadlineSentiment',\n 'NewsTitleSentiment',\n 'OccupancyDetectionLight',\n 'PPGDalia',\n 'ParkingBirmingham',\n 'PhosphorusConcentration',\n 'PotassiumConcentration',\n 'PrecipitationAndalusia',\n 'SierraNevadaMountainsSnow',\n 'SodiumConcentration',\n 'SolarRadiationAndalusia',\n 'SteamPredictor',\n 'SulphurConcentration',\n 'TetuanEnergyConsumption',\n 'VentilatorPressure',\n 'WaveDataTension',\n 'WindTurbinePower',\n 'ZincConcentration']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aeon.datasets.dataset_collections import get_available_tser_datasets\n",
    "\n",
    "get_available_tser_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:19.018724Z",
     "start_time": "2024-06-17T13:07:19.010510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X =  (673, 1, 266)  meta data =  {'problemname': 'floodmodeling1', 'timestamps': False, 'missing': False, 'univariate': True, 'equallength': True, 'classlabel': False, 'targetlabel': True, 'class_values': []}\n"
     ]
    }
   ],
   "source": [
    "X, y, meta = load_regression(\"FloodModeling1\", return_metadata=True)\n",
    "print(\"Shape of X = \", X.shape, \" meta data = \", meta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:19.115945Z",
     "start_time": "2024-06-17T13:07:19.020208Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Series Forecasting\n",
    "\n",
    "The [Monash time series forecasting](https://forecastingdata.org/) repo contains a\n",
    "large number of forecasting data, including competition data such as M1, M3 and M4.\n",
    "Usage is the same as the other problems, although there is no provided train/test\n",
    "splits.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['australian_electricity_demand_dataset',\n 'car_parts_dataset_with_missing_values',\n 'car_parts_dataset_without_missing_values',\n 'cif_2016_dataset',\n 'covid_deaths_dataset',\n 'covid_mobility_dataset_with_missing_values',\n 'covid_mobility_dataset_without_missing_values',\n 'dominick_dataset',\n 'elecdemand_dataset',\n 'electricity_hourly_dataset',\n 'electricity_weekly_dataset',\n 'fred_md_dataset',\n 'hospital_dataset',\n 'kaggle_web_traffic_dataset_with_missing_values',\n 'kaggle_web_traffic_dataset_without_missing_values',\n 'kaggle_web_traffic_weekly_dataset',\n 'kdd_cup_2018_dataset_with_missing_values',\n 'kdd_cup_2018_dataset_without_missing_values',\n 'london_smart_meters_dataset_with_missing_values',\n 'london_smart_meters_dataset_without_missing_values',\n 'm1_monthly_dataset',\n 'm1_quarterly_dataset',\n 'm1_yearly_dataset',\n 'm3_monthly_dataset',\n 'm3_other_dataset',\n 'm3_quarterly_dataset',\n 'm3_yearly_dataset',\n 'm4_daily_dataset',\n 'm4_hourly_dataset',\n 'm4_monthly_dataset',\n 'm4_quarterly_dataset',\n 'm4_weekly_dataset',\n 'm4_yearly_dataset',\n 'nn5_daily_dataset_with_missing_values',\n 'nn5_daily_dataset_without_missing_values',\n 'nn5_weekly_dataset',\n 'pedestrian_counts_dataset',\n 'saugeenday_dataset',\n 'solar_10_minutes_dataset',\n 'solar_4_seconds_dataset',\n 'solar_weekly_dataset',\n 'sunspot_dataset_with_missing_values',\n 'sunspot_dataset_without_missing_values',\n 'tourism_monthly_dataset',\n 'tourism_quarterly_dataset',\n 'tourism_yearly_dataset',\n 'traffic_hourly_dataset',\n 'traffic_weekly_dataset',\n 'us_births_dataset',\n 'weather_dataset',\n 'wind_4_seconds_dataset',\n 'wind_farms_minutely_dataset_with_missing_values',\n 'wind_farms_minutely_dataset_without_missing_values']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aeon.datasets.dataset_collections import get_available_tsf_datasets\n",
    "\n",
    "get_available_tsf_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:19.124403Z",
     "start_time": "2024-06-17T13:07:19.117901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23000, 3)\n",
      "{'frequency': 'yearly', 'forecast_horizon': 6, 'contain_missing_values': False, 'contain_equal_length': False}\n",
      "  series_name     start_timestamp  \\\n",
      "0          T1 1979-01-01 12:00:00   \n",
      "1          T2 1979-01-01 12:00:00   \n",
      "2          T3 1979-01-01 12:00:00   \n",
      "3          T4 1979-01-01 12:00:00   \n",
      "4          T5 1979-01-01 12:00:00   \n",
      "\n",
      "                                        series_value  \n",
      "0  [5172.1, 5133.5, 5186.9, 5084.6, 5182.0, 5414....  \n",
      "1  [2070.0, 2104.0, 2394.0, 1651.0, 1492.0, 1348....  \n",
      "2  [2760.0, 2980.0, 3200.0, 3450.0, 3670.0, 3850....  \n",
      "3  [3380.0, 3670.0, 3960.0, 4190.0, 4440.0, 4700....  \n",
      "4  [1980.0, 2030.0, 2220.0, 2530.0, 2610.0, 2720....  \n"
     ]
    }
   ],
   "source": [
    "X, metadata = load_forecasting(\"m4_yearly_dataset\", return_metadata=True)\n",
    "print(X.shape)\n",
    "print(metadata)\n",
    "data = X.head()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:21.595604Z",
     "start_time": "2024-06-17T13:07:19.126358Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Series Anomaly Detection (TSAD)\n",
    "\n",
    "The\n",
    "[TimeEval archive](https://timeeval.github.io/evaluation-paper/notebooks/Datasets.html)\n",
    "[5] contains 30 dataset collections for time series anomaly detection. Each collection\n",
    "consisting of many datasets from the same source. The collections are from a variety of\n",
    "domains, including cyber security, industrial processes, and healthcare. The datasets\n",
    "can directly be loaded using the `load_anomaly_detection` function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate length =  11233\n",
      "Multivariate length =  342\n"
     ]
    }
   ],
   "source": [
    "from aeon.datasets.tsad_datasets import multivariate, univariate\n",
    "\n",
    "# This file also contains sub lists by learning type, e.g. semi-supervised, ...\n",
    "print(\"Univariate length = \", len(univariate()))\n",
    "print(\"Multivariate length = \", len(multivariate()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:21.771910Z",
     "start_time": "2024-06-17T13:07:21.597146Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "A default train and test split is provided for all supervised and semi-supervised data.\n",
    "The file structure for a problem is\n",
    "\n",
    "        <extract_path>/<dimensionality>/<collection>/<dataset>.test.csv\n",
    "        <extract_path>/<dimensionality>/<collection>/<dataset>.train.csv\n",
    "\n",
    "You can load these problems directly from the TimeEval archive [5] into memory. The\n",
    "loading function can also return associated metadata in addition to the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X =  (16220, 18)\n",
      "Shape of y =  (16220,)\n",
      "\n",
      "Meta data =  {'problemname': 'Genesis genesis-anomalies', 'timestamps': 16220, 'dimensions': 18, 'learning_type': 'unsupervised', 'contamination': 0.00308261405672, 'num_anomalies': 3}\n"
     ]
    }
   ],
   "source": [
    "name = (\"Genesis\", \"genesis-anomalies\")\n",
    "X, y, meta = load_anomaly_detection(name, return_metadata=True)\n",
    "print(\"Shape of X = \", X.shape)\n",
    "print(\"Shape of y = \", y.shape)\n",
    "print(\"\\nMeta data = \", meta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:22.224850Z",
     "start_time": "2024-06-17T13:07:21.773453Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "[1] Dau et. al, The UCR time series archive, IEEE/CAA Journal of Automatica Sinica, 2019\n",
    "[2] Ruiz et. al, The great multivariate time series classification bake off: a review\n",
    "    and experimental evaluation of recent algorithmic advances, Data Mining and\n",
    "    Knowledge Discovery 35(2), 2021\n",
    "[3] Tan et. al, Time Series Extrinsic Regression, Data Mining and Knowledge\n",
    "    Discovery, 2021\n",
    "[4] Godahewa et. al, Monash Time Series Forecasting Archive,Neural Information\n",
    "    Processing Systems Track on Datasets and Benchmarks, 2021\n",
    "[5] Sebastian Schmidl, Phillip Wenig, Thorsten Papenbrock: Anomaly Detection in\n",
    "    Time Series: A Comprehensive Evaluation. PVLDB 9:(15), 2022,\n",
    "    DOI:10.14778/3538598.3538602."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:22.231563Z",
     "start_time": "2024-06-17T13:07:22.228483Z"
    }
   },
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
