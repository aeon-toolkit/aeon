{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data into aeon\n",
    "aeon supports a range of data input formats. Example problems are described in\n",
    "provided_data.ipyn. Downloading data is described in benchmarking_data.ipynb. You\n",
    "can of course load and format the data so that it conforms to the input types\n",
    "describe in data_storage. aeon also provides data formats for time series for both\n",
    "forecasting and machine learning. These are all text files with a particular\n",
    "structure. Both formats store a single time series per row.\n",
    "\n",
    "1. The `.ts` and `.tsf` format used by the aeon packages and the [time series](https://timeseriesclassification.com) and [forecasting](https://forecastingdata.org)\n",
    " repositories. More information on the `.tsf` format is\n",
    "[here](https://openreview.net/pdf?id=wEc1mgAjU-)\n",
    "Links to download all of the UCR univariate and the tsml multivariate data in `.ts`\n",
    "format.\n",
    "2. The `.arff` format used by Weka machine learning toolkit ([see](https://www.cs.waikato.ac.nz/~ml/weka/arff.html))\n",
    "Links to download all of the UCR univariate and the tsml multivariate data in `.arff`\n",
    "format.\n",
    "3. The `.tsv` format used by the UCR research group [see](https://www.cs.ucr\n",
    ".edu/~eamonn/time_series_data_2018).\n",
    "Link to download all of the UCR univariate IN `.tsv` format.\n",
    "\n",
    "The baked in datasets are described [here](provided_data.ipynb). Data\n",
    "structures to store the data are described [here](data_structures.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The .ts and .tsf file format\n",
    "\n",
    "The `.ts` and `.tsf` file formats can store time series with different\n",
    "characteristics and contain metadata in the header. `.ts` store collections of time\n",
    "series for classification, clustering and regression. They can store\n",
    "univariate/multivariate equal length/unequal length\n",
    "problems. `.tsf` files store collections of series for forecasting. This is the format\n",
    " of most of the baked in machine problem (link to notebook).\n",
    "\n",
    "Both file types allow for comments at the top of the file. All lines beginning with a\n",
    " hash (#) are comments. After the comments the files contain meta information about the data and the data itself."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Meta data for .ts and .tsf files\n",
    "\n",
    "The header information is used to store metadata. `.ts` files contain a\n",
    "subset of the following boolean flags:\n",
    "\n",
    "    @problemName <problem name>\n",
    "    @univariate <true/false>\n",
    "    @dimensions integer\n",
    "    @equalLength <true/false>\n",
    "    @seriesLength integer\n",
    "    @classLabel <true/false> <space delimited list of possible class values>\n",
    "    @targetlabel <true/false>\n",
    "    @data\n",
    "\n",
    "Note that these tags are not esssential, but they help understanding of the data.\n",
    " If they are not present they are inferred from the data. They are also not case\n",
    " sensitive. We use camel case in the files for readability, but internally,\n",
    " everything is stripped back to lower case. Note that only one of classlabel or\n",
    " targetlabel can be true. If class label is true, it indicates a classification\n",
    " problem, and the class values should follow the tag. Class values can be strings or integers. So, for example, the header for the PLAID dataset is\n",
    "\n",
    "    @problemName PLAID\n",
    "    @missing false\n",
    "    @univariate true\n",
    "    @equalLength false\n",
    "    @classLabel true 0 1 2 3 4 5 6 7 8 9 10\n",
    "\n",
    "this indicates that it is univariate (single channel per case), has no missing\n",
    "values, unequal length time series and is a 11 class classification problem. For\n",
    "more detail on our provided data, see [here](provided_data.ipynb).\n",
    "BasicMotions data header is as follows\n",
    "\n",
    "    @problemName BasicMotions\n",
    "    @missing false\n",
    "    @univariate false\n",
    "    @dimensions 6\n",
    "    @equalLength true\n",
    "    @seriesLength 100\n",
    "    @classLabel true Standing Running Walking Badminton\n",
    "\n",
    "This is a multivariate problem with six channels/dimensions, equal length series\n",
    "(length 100) with four classes. There is also a tag for @timeStamps, but this is not\n",
    "yet supported.\n",
    "\n",
    "`.tsf` files meta data begins with `@attribute` tags for each series. An\n",
    " @attribute is a series column name. Multiple `@attribute` tags correspond to\n",
    " hierarchical keys. Other possible tags include frequency, horizon, missing and\n",
    " equallength. For example\n",
    "\n",
    "    # Dataset Information\n",
    "    # This dataset is an aggregated version of the Ausgrid half hourly dataset.\n",
    "    # This file contains 299 weekly series representing the energy consumption of\n",
    "    # Australian households for the period of 2010-07-01 to 2013-06-26 under General\n",
    "    # Consumption (GC) category.\n",
    "    # The original Ausgrid dataset contains 300 half hourly series and one series was\n",
    "    # removed before aggregation due to the inclusion of missing values from\n",
    "    # 2012-10-10 to 2013-06-30.\n",
    "    #\n",
    "    # For more details, please refer to\n",
    "    # AusGrid, 2019. Solar home electricity data. Accessed: 2020-05-10.\n",
    "    # URL https://www.ausgrid.com.au/Industry/Our-Research/Data-to-share/Solar-home\n",
    "    # -electricity-data\n",
    "    #\n",
    "    @relation Ausgrid\n",
    "    @attribute series_name string\n",
    "    @attribute start_timestamp date\n",
    "    @frequency weekly\n",
    "    @horizon 8\n",
    "    @missing false\n",
    "    @equallength true\n",
    "\n",
    "this indicates each series has a string name and start time at the beginning, a\n",
    "weekly frequency, forecasting horizon of eight, no missing values and all series are\n",
    "the same length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data format for  `.ts`\n",
    "\n",
    "Data in both `.ts` and `.tsf` files begins after the `@data` tag. Each row contains\n",
    "data for a single time series.\n",
    "Values for a series are in a comma-separated ordered list. For `.ts` files, each\n",
    "series can be multivariate. Each dimension/channel is separated by a colon (:). The\n",
    "class value or target value are at the end of the series, and also separated by a\n",
    "colon. For example,\n",
    "\n",
    "    @problemName example1\n",
    "    @missing false\n",
    "    @univariate true\n",
    "    @equalLength true\n",
    "    @seriesLength 4\n",
    "    @classLabel true 1 2\n",
    "    @data\n",
    "    2,3,2,4:1\n",
    "    13,12,32,12:1\n",
    "    4,4,5,4:2\n",
    "\n",
    "has 3 cases of univariate series, length 4 with class values 1, 1 and 2. Missing\n",
    "readings are indicated by `?`. For example, this regression dataset has three\n",
    "dimensions, unequal length series and contains missing values.\n",
    "\n",
    "    @problemName example2\n",
    "    @missing true\n",
    "    @univariate false\n",
    "    @dimensions 3\n",
    "    @equalLength false\n",
    "    @targetlabel true\n",
    "    @data\n",
    "    2,3,2,4: 5,6,7,7: 8,2,?,5:62\n",
    "    13,?,32,12,25: 6,6,6,6,?,8: 9,8,7,5,5:55"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data format for  `.tsf`\n",
    "The attributes are separated by colons, and the data follows. For example\n",
    "\n",
    "    @relation test\n",
    "    @attribute series_name string\n",
    "    @attribute start_timestamp date\n",
    "    @frequency yearly\n",
    "    @horizon 4\n",
    "    @missing false\n",
    "    @equallength false\n",
    "    @data\n",
    "    T1:1979-01-01 00-00-00:25092.2284,24271.5134,25828.9883,27697.5047,27956.2276,29924.4321,30216.8321\n",
    "    T2:1979-01-01 00-00-00:887896.51,887068.98,971549.04\n",
    "    T3:1973-01-01 00-00-00:227921,230995,183635,238605,254186\n",
    "\n",
    "contains three series called T1, T2 and T3, each with a start data 1/1/1979. The data\n",
    " is yearly, and not of equal length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading `.ts` and `.tsf` Data\n",
    "\n",
    "The TSC data comes with a predefined train/test split, and so each problem is\n",
    "stored in two files with suffix `_TRAIN.ts` and `_TEST.ts`. By default, each\n",
    "problem is stored in its own directory. If a data is stored on disk, it can be loaded\n",
    " from a `.ts` file using the method in aeon.datasets:\n",
    "\n",
    "    load_from_tsfile(full_file_path_and_name, replace_missing_vals_with='NaN')\n",
    "\n",
    "For example, the ArrowHead problem that is included in aeon under\n",
    "aeon/datasets/data  has this header\n",
    "\n",
    "    @problemName ArrowHead\n",
    "    @classLabel true 0 1 2\n",
    "    @univariate true\n",
    "    @missing false\n",
    "    @data\n",
    "and can be loaded with load_from_tsfile as follows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:32:13.134330Z",
     "iopub.status.busy": "2020-12-19T14:32:13.133562Z",
     "iopub.status.idle": "2020-12-19T14:32:13.811083Z",
     "shell.execute_reply": "2020-12-19T14:32:13.811445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1.9077772, -1.9048903, -1.8885626, -1.8711639, -1.8316792])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import aeon\n",
    "from aeon.datasets import load_from_tsfile\n",
    "\n",
    "DATA_PATH = os.path.join(os.path.dirname(aeon.__file__), \"datasets/data\")\n",
    "\n",
    "train_x, train_y = load_from_tsfile(DATA_PATH + \"/ArrowHead/ArrowHead_TRAIN.ts\")\n",
    "test_x, test_y = load_from_tsfile(DATA_PATH + \"/ArrowHead/ArrowHead_TEST.ts\")\n",
    "test_x[0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test partitions of the ArrowHead problem have been loaded into 3D numpy\n",
    "arrays with an associated array of class values. Further info on data structures is\n",
    "given in [this notebook](data_structures.ipynb). Datasets that are shipped with aeon\n",
    "(like ArrowHead, BasicMotions and PLAID) can be more simply loaded with bespoke\n",
    "functions. More details [here](provided_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:32:13.828436Z",
     "iopub.status.busy": "2020-12-19T14:32:13.823584Z",
     "iopub.status.idle": "2020-12-19T14:32:13.831026Z",
     "shell.execute_reply": "2020-12-19T14:32:13.831523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape =  (36, 1, 251)  test shape =  (175, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "from aeon.datasets import load_arrow_head, load_basic_motions, load_plaid\n",
    "\n",
    "train_x, train_y = load_arrow_head(split=\"TRAIN\")\n",
    "test_x, test_y = load_arrow_head(split=\"test\")\n",
    "X, y = load_basic_motions()\n",
    "plaid_train, _ = load_plaid(split=\"train\")\n",
    "print(\"Train shape = \", train_x.shape, \" test shape = \", test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading directly from [tsc.com](https://timeseriesclassification.com)\n",
    "\n",
    "You can also load `.ts` data directly from [tsc.com] (https://timeseriesclassification.com)\n",
    "using the function\n",
    "    def load_classification(name, split=None, extract_path=None, return_metadata=False):\n",
    "This function downloads the zip file from the website, unpacks it in the specified\n",
    "directory. It does not download if the file is already in the\n",
    "extract_path or in aeon/datasets/data.  If you do not give an extract path, it looks\n",
    "in aeon/datasets/data then writes to aeon/datasets/local_data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (211, 1, 251)\n",
      " Meta data =  {'problemname': 'arrowhead', 'timestamps': False, 'missing': False, 'univariate': True, 'equallength': True, 'classlabel': True, 'targetlabel': False, 'class_values': ['0', '1', '2']}\n"
     ]
    }
   ],
   "source": [
    "from aeon.datasets import load_classification\n",
    "\n",
    "# This will not download, because Arrowhead is already in the directory.\n",
    "# Change the extract path or name to downloads\n",
    "X, y, meta_data = load_classification(\"ArrowHead\", return_metadata=True)\n",
    "print(\" Shape of X = \", X.shape)\n",
    "print(\" Meta data = \", meta_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For more details, see the [Load from web](load_data_from_web.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Writing .ts files\n",
    "\n",
    "You can write data to a `.ts` file by calling the function `write_to_tsfile` in the\n",
    "datasets module. It has the following method signature:\n",
    "\n",
    "def write_to_tsfile(\n",
    "    X, path, y=None, problem_name=\"sample_data.ts\", header=None, regression=False\n",
    "):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weka .ARFF files\n",
    "\n",
    "The [Weka Java toolkit](https://www.cs.waikato.ac.nz/ml/weka/) uses a file format\n",
    "called Attribute-Relation File Format (ARFF) that was the original basis for the `.ts` and\n",
    "`.tsf` format. Information on `.arff` files can be found [here](https://www.cs.waikato.ac.nz/~ml/weka/arff.html) arff files can be used to store equal length univariate\n",
    "and multivariate problems. They cannot handle unequal length series.\n",
    "\n",
    "### Loading from Weka ARFF files\n",
    "\n",
    "It is also possible to load data from Weka's attribute-relation file format (ARFF) files. Data for timeseries problems are made available in this format  at www.timeseriesclassification.com. The `load_from_arff_file` method in `aeon.datasets` supports reading data for both univariate and multivariate timeseries problems.\n",
    "\n",
    "For example, we can load the ArrowHead data from an arff file rather than a `.ts` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:32:13.840562Z",
     "iopub.status.busy": "2020-12-19T14:32:13.840050Z",
     "iopub.status.idle": "2020-12-19T14:32:13.869367Z",
     "shell.execute_reply": "2020-12-19T14:32:13.869937Z"
    }
   },
   "outputs": [],
   "source": [
    "from aeon.datasets import load_from_arff_file\n",
    "\n",
    "X, y = load_from_arff_file(os.path.join(DATA_PATH, \"ArrowHead/ArrowHead_TRAIN.arff\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ucr .tsv files\n",
    "\n",
    "A further option is to load data into aeon from tab separated value (`.tsv`) files.\n",
    "Researchers at the University of Riverside, California make a variety of timeseries\n",
    "data available in this format at [Eamonn Keogh's website](https://www.cs.ucr\n",
    ".edu/~eamonn/time_series_data_2018). Each row is a time series, and the class value\n",
    "is the first one.\n",
    "\n",
    "The `load_from_tsv_file` method in `aeon.datasets` supports reading\n",
    "univariate problems. An example with ArrowHead is given below to demonstrate equivalence with loading from the .ts and ARFF file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T14:32:13.958719Z",
     "iopub.status.busy": "2020-12-19T14:32:13.958207Z",
     "iopub.status.idle": "2020-12-19T14:32:13.991444Z",
     "shell.execute_reply": "2020-12-19T14:32:13.992003Z"
    }
   },
   "outputs": [],
   "source": [
    "from aeon.datasets import load_from_tsv_file\n",
    "\n",
    "X, y = load_from_tsv_file(os.path.join(DATA_PATH, \"ArrowHead/ArrowHead_TRAIN.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
