{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data structures and containers to use for aeon estimators\n",
    "\n",
    "aeon includes algorithms for time series forecasting and machine learning. These two\n",
    "communities have different conventions on how to store data and what to call data\n",
    "structures. Some of the differences are\n",
    "\n",
    "1. Forecasters almost always stores data in pandas data structures, whereas machine\n",
    "learners use numpy arrays almost exclusively.\n",
    "2. n forecasting a 2 dimensional data is almost always shape `(n_timepoints, n_timeseries)` whereas in\n",
    "machine learning we would tend to store data in a `(n_timeseries, n_timepoints)`  array.\n",
    "3. In forecasting, a variable `y` refers to a time series for which we are attempting\n",
    " to make a forecast, hence `y` is assumed to be ordered. In machine learning,\n",
    " `y` is a list of either class labels (for classification) or observations of a\n",
    " response vairable (for regression). The ordering of values in `y` is determined by\n",
    " the ordering of the `X` input.\n",
    "\n",
    "Because of these sources of confusion, we recommend that you store data in\n",
    "pandas data structures for forecasting and numpy arrays for machine learning. We\n",
    "support other data containers, see the [data conversion page](data_conversions.ipynb)\n",
    " for more info."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forecasting data\n",
    "\n",
    "aeon forecasting uses `pd.Series`, `pd.DataFrame` and `pd.Multiindex` to store data.\n",
    "`pd.Series` are used to store a univariate time series with entries corresponding to\n",
    "different time points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "5    120.0\n6    140.0\n7    160.0\ndtype: float64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forecasting data in a pandas.Series\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aeon.forecasting.trend import TrendForecaster\n",
    "\n",
    "y = pd.Series([20.0, 40.0, 60.0, 80.0, 100.0])\n",
    "forecaster = TrendForecaster()\n",
    "forecaster.fit(y)  # fit the forecaster\n",
    "forecaster.predict(fh=[1, 2, 3])  # forecast the next 3 values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:30.451851772Z",
     "start_time": "2023-09-25T16:36:29.906931878Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`pd.DataFrame` are used to store multiple time series, where each column is a time\n",
    "series, and each row corresponds to a different, distinct time point. The index\n",
    "is the time point and should be monotonic. This creates two series called Sales and\n",
    "Temperature, and stores observations for time points 0,1,2,3,4,5."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sales  Temperature\n",
      "0    111           26\n",
      "1    100           21\n",
      "2     90           19\n",
      "3     80           14\n",
      "4     65           12\n",
      "5     89           22\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ExponentialSmoothing requires package 'statsmodels' to be present in the python environment, but 'statsmodels' was not found. 'statsmodels' is a soft dependency and not included in the base aeon installation. Please run: `pip install statsmodels` to install the statsmodels package. To install all soft dependencies, run: `pip install aeon[all_extras]`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/projects/aeon/aeon/utils/validation/_dependencies.py:118\u001B[0m, in \u001B[0;36m_check_soft_dependencies\u001B[0;34m(package_import_alias, severity, obj, suppress_import_stdout, *packages)\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m         pkg_ref \u001B[38;5;241m=\u001B[39m \u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpackage_import_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;66;03m# if package cannot be imported, make the user aware of installation requirement\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/importlib/__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1014\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:991\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:973\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'statsmodels'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(ice_creams)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maeon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mforecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexp_smoothing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExponentialSmoothing\n\u001B[0;32m---> 10\u001B[0m forecaster \u001B[38;5;241m=\u001B[39m \u001B[43mExponentialSmoothing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m forecaster\u001B[38;5;241m.\u001B[39mfit(ice_creams)\n\u001B[1;32m     12\u001B[0m forecaster\u001B[38;5;241m.\u001B[39mpredict(fh\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m])\n",
      "File \u001B[0;32m~/projects/aeon/aeon/forecasting/exp_smoothing.py:167\u001B[0m, in \u001B[0;36mExponentialSmoothing.__init__\u001B[0;34m(self, trend, damped_trend, seasonal, sp, initial_level, initial_trend, initial_seasonal, use_boxcox, initialization_method, smoothing_level, smoothing_trend, smoothing_seasonal, damping_trend, optimized, remove_bias, start_params, method, minimize_kwargs, use_brute, random_state)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mminimize_kwargs \u001B[38;5;241m=\u001B[39m minimize_kwargs\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_brute \u001B[38;5;241m=\u001B[39m use_brute\n\u001B[0;32m--> 167\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/aeon/aeon/forecasting/base/adapters/_statsmodels.py:34\u001B[0m, in \u001B[0;36m_StatsModelsAdapter.__init__\u001B[0;34m(self, random_state)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state \u001B[38;5;241m=\u001B[39m random_state\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fitted_forecaster \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_StatsModelsAdapter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/aeon/aeon/forecasting/base/_base.py:117\u001B[0m, in \u001B[0;36mBaseForecaster.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_converter_store_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()  \u001B[38;5;66;03m# storage dictionary for in/output conversion\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28msuper\u001B[39m(BaseForecaster, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m--> 117\u001B[0m \u001B[43m_check_estimator_deps\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/aeon/aeon/utils/validation/_dependencies.py:364\u001B[0m, in \u001B[0;36m_check_estimator_deps\u001B[0;34m(obj, msg, severity)\u001B[0m\n\u001B[1;32m    362\u001B[0m     pkg_deps \u001B[38;5;241m=\u001B[39m [pkg_deps]\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pkg_deps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 364\u001B[0m     pkg_deps_ok \u001B[38;5;241m=\u001B[39m \u001B[43m_check_soft_dependencies\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpkg_deps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseverity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseverity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    365\u001B[0m     compatible \u001B[38;5;241m=\u001B[39m compatible \u001B[38;5;129;01mand\u001B[39;00m pkg_deps_ok\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compatible\n",
      "File \u001B[0;32m~/projects/aeon/aeon/utils/validation/_dependencies.py:140\u001B[0m, in \u001B[0;36m_check_soft_dependencies\u001B[0;34m(package_import_alias, severity, obj, suppress_import_stdout, *packages)\u001B[0m\n\u001B[1;32m    130\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    131\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires package \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to be present \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min the python environment, but \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m was not found. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maeon[all_extras]`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    138\u001B[0m     )\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m severity \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m severity \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarning\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    142\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: ExponentialSmoothing requires package 'statsmodels' to be present in the python environment, but 'statsmodels' was not found. 'statsmodels' is a soft dependency and not included in the base aeon installation. Please run: `pip install statsmodels` to install the statsmodels package. To install all soft dependencies, run: `pip install aeon[all_extras]`"
     ]
    }
   ],
   "source": [
    "ice_creams = {\n",
    "    \"Sales\": [111, 100, 90, 80, 65, 89],\n",
    "    \"Temperature\": [26, 21, 19, 14, 12, 22],\n",
    "}\n",
    "# Create DataFrame\n",
    "ice_creams = pd.DataFrame(ice_creams)\n",
    "print(ice_creams)\n",
    "from aeon.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "\n",
    "forecaster = ExponentialSmoothing()\n",
    "forecaster.fit(ice_creams)\n",
    "forecaster.predict(fh=[1, 2, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:30.808972282Z",
     "start_time": "2023-09-25T16:36:30.450980475Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can add a date-time index, and this is required by some forecasters (e.g. Prophet)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ice_creams[\"datetime\"] = pd.to_datetime(\n",
    "    [\n",
    "        \"01-06-2018 23:15:00\",  # Creating data\n",
    "        \"02-09-2019 01:48:00\",\n",
    "        \"08-06-2020 13:20:00\",\n",
    "        \"07-03-2021 14:50:00\",\n",
    "        \"07-06-2022 11:50:00\",\n",
    "        \"03-05-2023 16:50:00\",\n",
    "    ]\n",
    ")\n",
    "ice_creams = ice_creams.set_index(\"datetime\")\n",
    "print(ice_creams)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-25T16:36:30.806065207Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`pd.DataFrame` also have the capability to store multiple indexes, which can be used\n",
    "to represent whats called Panel data in forecasting hierarchical data. A Panel is a\n",
    "collection of (possibly) multivariate data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                            c0\nh0   h1   time                \nh0_0 h1_0 2000-01-01  2.211608\n          2000-01-02  3.068498\n          2000-01-03  3.925924\n          2000-01-04  2.900095\n          2000-01-05  4.324984",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>c0</th>\n    </tr>\n    <tr>\n      <th>h0</th>\n      <th>h1</th>\n      <th>time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">h0_0</th>\n      <th rowspan=\"5\" valign=\"top\">h1_0</th>\n      <th>2000-01-01</th>\n      <td>2.211608</td>\n    </tr>\n    <tr>\n      <th>2000-01-02</th>\n      <td>3.068498</td>\n    </tr>\n    <tr>\n      <th>2000-01-03</th>\n      <td>3.925924</td>\n    </tr>\n    <tr>\n      <th>2000-01-04</th>\n      <td>2.900095</td>\n    </tr>\n    <tr>\n      <th>2000-01-05</th>\n      <td>4.324984</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aeon.utils._testing.hierarchical import _make_hierarchical\n",
    "\n",
    "y = _make_hierarchical()\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:31.101400666Z",
     "start_time": "2023-09-25T16:36:31.086676930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                            c0\nh0   h1   time                \nh0_0 h1_0 2000-01-13  1.812590\n          2000-01-14  1.668527\n     h1_1 2000-01-13  3.445072\n          2000-01-14  3.419808\n     h1_2 2000-01-13  3.068927\n          2000-01-14  2.974026\n     h1_3 2000-01-13  3.888089\n          2000-01-14  3.980505\nh0_1 h1_0 2000-01-13  4.068846\n          2000-01-14  4.208284\n     h1_1 2000-01-13  3.588580\n          2000-01-14  3.560109\n     h1_2 2000-01-13  2.493876\n          2000-01-14  2.344370\n     h1_3 2000-01-13  2.224848\n          2000-01-14  2.020582",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>c0</th>\n    </tr>\n    <tr>\n      <th>h0</th>\n      <th>h1</th>\n      <th>time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">h0_0</th>\n      <th rowspan=\"2\" valign=\"top\">h1_0</th>\n      <th>2000-01-13</th>\n      <td>1.812590</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>1.668527</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">h1_1</th>\n      <th>2000-01-13</th>\n      <td>3.445072</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>3.419808</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">h1_2</th>\n      <th>2000-01-13</th>\n      <td>3.068927</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>2.974026</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">h1_3</th>\n      <th>2000-01-13</th>\n      <td>3.888089</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>3.980505</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">h0_1</th>\n      <th rowspan=\"2\" valign=\"top\">h1_0</th>\n      <th>2000-01-13</th>\n      <td>4.068846</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>4.208284</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">h1_1</th>\n      <th>2000-01-13</th>\n      <td>3.588580</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>3.560109</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">h1_2</th>\n      <th>2000-01-13</th>\n      <td>2.493876</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>2.344370</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">h1_3</th>\n      <th>2000-01-13</th>\n      <td>2.224848</td>\n    </tr>\n    <tr>\n      <th>2000-01-14</th>\n      <td>2.020582</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.fit(y, fh=[1, 2]).predict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:31.461533859Z",
     "start_time": "2023-09-25T16:36:31.293481479Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`np.ndarray` can be used with the forecasters in aeon, although we recommend using\n",
    "pandas. One dimensional np.ndarray are treated as a single time series. 2D numpy\n",
    "array are treated as multiple series of shape `(n_timeseries, n_timepoints)`.\n",
    "Forecasters fit independently on each series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[120.],\n       [140.],\n       [160.]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([20.0, 40.0, 60.0, 80.0, 100.0])\n",
    "forecaster = TrendForecaster()\n",
    "forecaster.fit(y)  # fit the forecaster\n",
    "forecaster.predict(fh=[1, 2, 3])  # forecast the next 3 values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:31.610660640Z",
     "start_time": "2023-09-25T16:36:31.551074771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[120.,  50.],\n       [140.,  40.],\n       [160.,  30.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[20.0, 40.0, 60.0, 80.0, 100.0], [100.0, 90.0, 80.0, 70.0, 60.0]])\n",
    "y = y.transpose()\n",
    "forecaster = TrendForecaster()\n",
    "forecaster.fit(y)  # fit the forecaster\n",
    "forecaster.predict(fh=[1, 2, 3])  # forecast the next 3 values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:31.790848688Z",
     "start_time": "2023-09-25T16:36:31.773427453Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine learning data\n",
    "\n",
    "Machine learning algorithms generally use collections of instances or cases stored as\n",
    " numpy arrays. Like scikit-learn, pytorch and keras, we primarily use numpy arrays.\n",
    " A collection contains a number of time series cases (or just cases) which we refer\n",
    " to in code as `n_cases`. Each case contains a number of time series observations,\n",
    " which we denote `n_timepoints`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape =  (2, 1, 5)  First series = [[ 20.  40.  60.  80. 100.]] second series =  [[100.  90.  80.  70.  60.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [[20.0, 40.0, 60.0, 80.0, 100.0]],  # Univariate series as 3D array\n",
    "        [[100.0, 90.0, 80.0, 70.0, 60.0]],\n",
    "    ]\n",
    ")  # n_cases = 2, n_channels =1, n_timepoints = 5\n",
    "print(\"X shape = \", X.shape, \" First series =\", X[0], \"second series = \", X[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:31.980113275Z",
     "start_time": "2023-09-25T16:36:31.973496884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape =  (4, 3, 4) \n",
      " First series =\n",
      " [[ 20.   40.  600.   55. ]\n",
      " [ 10.   11.   12.   11. ]\n",
      " [ -4.    1.    6.6   2. ]] \n",
      "second series = \n",
      " [[ 10.  90.  80. 100.]\n",
      " [ 14.  70.  60.  22.]\n",
      " [ 49.  49.  66.   9.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0, 1, 1, 1])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [[20, 40, 600, 55], [10, 11, 12, 11], [-4, 1, 6.6, 2]],\n",
    "        [[10, 90, 80, 100], [14, 70, 60, 22], [49, 49, 66, 9]],\n",
    "        [[14, 6, 10, -401], [44, 70, 60, 22], [49, 52, 33, 49]],\n",
    "        [[22, 93, 18, 100], [34, 170, 0, 87], [49, 49, 33, 49]],\n",
    "    ]\n",
    ")\n",
    "# n_cases = 4, n_channels =3, n_timepoints = 4\n",
    "print(\"X shape = \", X.shape, \"\\n First series =\\n\", X[0], \"\\nsecond series = \\n\", X[1])\n",
    "from aeon.clustering import TimeSeriesKMeans\n",
    "\n",
    "kmeans = TimeSeriesKMeans(distance=\"euclidean\", n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "kmeans.predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:37.922823224Z",
     "start_time": "2023-09-25T16:36:32.069055133Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The target variable for classification should be stored as a np.ndarray of integers\n",
    "or strings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['pass', 'pass', 'fail', 'fail'], dtype='<U4')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1, 1, 0, 0])\n",
    "y2 = np.array([\"pass\", \"pass\", \"fail\", \"fail\"])\n",
    "from aeon.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "knn = KNeighborsTimeSeriesClassifier(distance=\"dtw\")\n",
    "knn.fit(X, y)\n",
    "knn.fit(X, y2)\n",
    "knn.predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:37.957349822Z",
     "start_time": "2023-09-25T16:36:37.921663994Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For regression, the target variable should be of type float\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.5,  4.3, -2. , 10. ])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1.5, 4.3, -2.0, 10])\n",
    "from aeon.regression.distance_based import KNeighborsTimeSeriesRegressor\n",
    "\n",
    "knn_r = KNeighborsTimeSeriesRegressor(distance=\"dtw\")\n",
    "knn_r.fit(X, y)\n",
    "knn_r.predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:37.964863340Z",
     "start_time": "2023-09-25T16:36:37.958316827Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the time series are not all equal length, they should be stored as a list of 2D\n",
    "numpy arrays. Some estimators can deal with unequal length series. Those that can't\n",
    "will raise an exception if passed unequal length series. Note we assume that channels\n",
    " are all the same length for any given series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 1])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = np.array([[20, 40, 60, 55, 66], [10, 11, 12, 11, 66], [-4, 15, 6.6, 12, 44]])\n",
    "x1 = np.array([[10, 90, 80], [70, 60, 22], [49, 66, 9]])\n",
    "x2 = np.array([[22, 93, 18, 100], [34, 170, 0, 87], [49, 49, 33, 49]])\n",
    "X_uneq = []\n",
    "X_uneq.append(x0)\n",
    "X_uneq.append(x1)\n",
    "X_uneq.append(x2)\n",
    "y = np.array([0, 0, 1])\n",
    "knn.fit(X_uneq, y)\n",
    "knn.predict(X_uneq)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T16:36:39.277202857Z",
     "start_time": "2023-09-25T16:36:37.967750836Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "aeon has several standard problems baked in, and facilities for loading data from\n",
    "external sources. Please see [the data loading notebook](data_loading.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
