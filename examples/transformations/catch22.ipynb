{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Canonical Time-series Characteristics (catch22) transform\n",
    "\n",
    "Catch22\\[1\\] is a collection of 22 time series features extracted from the 7000+ present in the _hctsa_ \\[2\\]\\[3\\] toolbox.\n",
    "A hierarchical clustering was performed on the correlation matrix of features that performed better than random chance to remove redundancy.\n",
    "These clusters were sorted by balanced accuracy using a decision tree classifier and a single feature was selected from the 22 clusters formed, taking into account balanced accuracy results, computational efficiency and interpretability.\n",
    "More about the individual features of catch22 can be learned in the [Gitbook](https://time-series-features.gitbook.io/catch22/information-about-catch22/feature-descriptions) of the original creators.\n",
    "\n",
    "In this notebook, we will demonstrate how to use aeon's catch22 transformer on the ItalyPowerDemand univariate and BasicMotions multivariate datasets. We will go through the parameters of catch22 and how changing the default values may change results. Catch22 has also been used inside of [classification](../classification/feature_based.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catch22 is a feature based transformer that extracts 22 features from a time series. The input data can be both univariate and multivariate, without the need to reshape the data. It is most commonly used for interpretability of each time series data. Additionally, as the data of a time series will be reduced to 22 data values, it will increase computational efficiency of machine learning tasks such as clustering, classification, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Data and Catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from aeon.datasets import load_basic_motions, load_italy_power_demand\n",
    "from aeon.transformations.collection.feature_based import Catch22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy Power Demand (Univariate):  (67, 1, 24) (67,) (1029, 1, 24) (1029,)\n",
      "Load Basic Motions (Multivarite):  (40, 6, 100) (40,) (40, 6, 100) (40,)\n"
     ]
    }
   ],
   "source": [
    "IPD_X_train, IPD_y_train = load_italy_power_demand(split=\"train\")\n",
    "IPD_X_test, IPD_y_test = load_italy_power_demand(split=\"test\")\n",
    "\n",
    "print(\n",
    "    \"Italy Power Demand (Univariate): \",\n",
    "    IPD_X_train.shape,\n",
    "    IPD_y_train.shape,\n",
    "    IPD_X_test.shape,\n",
    "    IPD_y_test.shape,\n",
    ")\n",
    "\n",
    "BM_X_train, BM_y_train = load_basic_motions(split=\"train\")\n",
    "BM_X_test, BM_y_test = load_basic_motions(split=\"test\")\n",
    "\n",
    "print(\n",
    "    \"Load Basic Motions (Multivarite): \",\n",
    "    BM_X_train.shape,\n",
    "    BM_y_train.shape,\n",
    "    BM_X_test.shape,\n",
    "    BM_y_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Transform the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 22)\n"
     ]
    }
   ],
   "source": [
    "c22_uv = Catch22()\n",
    "c22_uv.fit(IPD_X_train, IPD_y_train)\n",
    "transformed_data_uv = c22_uv.transform(IPD_X_train)\n",
    "print(transformed_data_uv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do note that the result of the shape won't be (X , 22). This is because it's a multivariate dataset, and therefore the feature vector will be of size 22 times the number of channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 132)\n"
     ]
    }
   ],
   "source": [
    "c22_mv = Catch22()\n",
    "data = c22_mv.fit_transform(BM_X_train, BM_y_train)\n",
    "transformed_data_mv = c22_uv.transform(BM_X_train)\n",
    "print(transformed_data_mv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aeon's catch22 includes a lot options for users need compared to the original catch22 implementation which we will talk about in section 2.4. Few of the parameters are shown below with examples, specifically the ones that change affect the output. More can be found in [catch22's documentation](../../docs/api_reference/transformations.rst)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catch22 takes 22 distinct features from a time series. Sometimes you may not need all the features extracted by catch22, instead you may only need some very specific features. By defining an array containing strings of features, only those specified features will be extracted. The order of these features do matter, as that will be the order of the output. Aeon's [catch22's documentation](../../docs/api_reference/transformations.rst) specifies a list of the 22 features for extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid feature selection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m c22_short \u001b[38;5;241m=\u001b[39m Catch22(features\u001b[38;5;241m=\u001b[39mfeatures_short)\n\u001b[0;32m     10\u001b[0m c22_short\u001b[38;5;241m.\u001b[39mfit(IPD_X_train, IPD_y_train)\n\u001b[1;32m---> 11\u001b[0m transformed_data_short \u001b[38;5;241m=\u001b[39m \u001b[43mc22_short\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIPD_X_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(transformed_data_short\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\AeonProject\\aeon\\.venv\\Lib\\site-packages\\aeon\\transformations\\collection\\base.py:157\u001b[0m, in \u001b[0;36mBaseCollectionTransformer.transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    154\u001b[0m X_inner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_collection(X, store_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m y_inner \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m--> 157\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_inner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[1;32md:\\AeonProject\\aeon\\.venv\\Lib\\site-packages\\aeon\\transformations\\collection\\feature_based\\_catch22.py:182\u001b[0m, in \u001b[0;36mCatch22._transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X into the catch22 features.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    The catch22 features for each dimension.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m n_cases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n\u001b[1;32m--> 182\u001b[0m f_idx \u001b[38;5;241m=\u001b[39m \u001b[43m_verify_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatch24\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m threads_to_use \u001b[38;5;241m=\u001b[39m check_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_pycatch22:\n",
      "File \u001b[1;32md:\\AeonProject\\aeon\\.venv\\Lib\\site-packages\\aeon\\transformations\\collection\\feature_based\\_catch22.py:1300\u001b[0m, in \u001b[0;36m_verify_features\u001b[1;34m(features, catch24)\u001b[0m\n\u001b[0;32m   1298\u001b[0m         f_idx\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m23\u001b[39m)\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid feature selection.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m f \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m22\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid feature selection."
     ]
    }
   ],
   "source": [
    "features_long = [\"DN_HistogramMode_5\", \"CO_f1ecac\", \"FC_LocalSimple_mean3_stderr\"]\n",
    "features_short = [\"mode_5\", \"acf_timescale\", \"forecast_error\"]\n",
    "\n",
    "c22_long = Catch22(features=features_long)\n",
    "c22_long.fit(IPD_X_train, IPD_y_train)\n",
    "transformed_data_long = c22_long.transform(IPD_X_train)\n",
    "print(transformed_data_long.shape)\n",
    "\n",
    "c22_short = Catch22(features=features_short)\n",
    "c22_short.fit(IPD_X_train, IPD_y_train)\n",
    "transformed_data_short = c22_short.transform(IPD_X_train)\n",
    "print(transformed_data_short.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Catch24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catch24 extracts 24 features from a time series. The 24 features consist of the 22 features from catch22 with the addition of the mean and standard deviation of the time series. More features does not strictly define better results, as it may increase run time and overfit the data in certain time series tasks. In certain tasks, catch24 may outperform catch22. For example in \\[4\\], catch24 significally outperformed catch22 in cross-domain anomaly detection.\n",
    "\n",
    "Catch22 extracts the most important features for machine learning tasks and therefore is more widely used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 24)\n"
     ]
    }
   ],
   "source": [
    "c24 = Catch22(catch24=True)\n",
    "data_c24 = c24.fit_transform(IPD_X_train)\n",
    "print(data_c24.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Replace NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find that some time series cannot extract certain features from it. This may happen when division by zero occurs, or the input value is zero. Simply, it means we cannot extract the feature from the time series. However, we may still want a number for calculations and therefore 'replace_nans' allows us to replace NaN with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with NaN: [       nan        nan 1.         0.         0.         6.\n",
      " 6.         0.                nan 0.         0.         0.\n",
      " 3.         0.         1.         1.60943791 1.                nan\n",
      "        nan        nan 0.08       0.        ]\n",
      "\n",
      "Data with no NaN:  [0.         0.         1.         0.         0.         6.\n",
      " 6.         0.         0.         0.         0.         0.\n",
      " 3.         0.         1.         1.60943791 1.         0.\n",
      " 0.         0.         0.08       0.        ]\n"
     ]
    }
   ],
   "source": [
    "training_data = np.array([[0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "c22_nan = Catch22()\n",
    "data_nan = c22_nan.fit_transform(training_data)\n",
    "print(f\"Data with NaN: {data_nan[0]}\\n\")\n",
    "\n",
    "c22_no_nan = Catch22(replace_nans=True)\n",
    "data_no_nan = c22_no_nan.fit_transform(training_data)\n",
    "print(\"Data with no NaN: \", data_no_nan[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Pycatch22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pycatch22 is the original implementation of catch22 based on \\[1\\]. Aeon allows you to use pycatch22 by setting the parameter 'use_pycatch22' to true. The difference of the two is that pycatch22 uses C as their backend while python uses the Numba library, which assembles python code into C. Aeon also regularly maintains their catch22 library, and therefore there should be barely any discrepancy between outputs. Pycatch22 has a few issues with their implementation such as at times struggling to run on windows. If you are using the aeon library for a certain task, but want to use pycatch22 for transformation of the data, it is recommended to use aeon's catch22 with the parameter 'use_pycatch22' set to true. If you do that, you may encounter a warning that pycatch22 has not been installed and therefore will use aeon's catch22, if that happens just install the pycatch22 library.\n",
    "\n",
    "Currently, pycatch22 has an issue where the output features extracted using Python yield different values compared to those extracted using the native C code. Aeon's catch22 implementation extracts the same results as pycatch22's C code. Therefore, the extracted results may differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pycatch22 :  [-0.57058807 -0.73624268  4.          0.625      -0.45833333  2.45190656\n",
      "  6.          0.42507544  0.58904862  0.92048041  0.11344743  0.37262397\n",
      "  3.          0.86956522  6.          1.81200059  0.75        0.15104572\n",
      "  0.          0.          0.04        0.        ]\n",
      "aeon catch22 :  [ 0.09203038 -0.73624265  7.          0.625      -0.45833333  3.\n",
      "  6.          0.42507544  0.58904862  0.8982969   0.11344743  0.37262397\n",
      "  3.          0.86956522  4.          1.83902118  0.75        0.15104572\n",
      "         nan         nan  0.06666667  0.        ]\n"
     ]
    }
   ],
   "source": [
    "py22 = Catch22(use_pycatch22=True)\n",
    "data_py22 = py22.fit_transform(IPD_X_test)\n",
    "print(f\"Pycatch22 : {data_py22[667]}\\n\")\n",
    "\n",
    "py22 = Catch22()\n",
    "data_py22 = py22.fit_transform(IPD_X_test)\n",
    "print(\"aeon catch22 : \", data_py22[667])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. References:\n",
    "\n",
    "\\[1\\] Lubba, C. H., Sethi, S. S., Knaute, P., Schultz, S. R., Fulcher, B. D., & Jones, N. S. (2019). catch22: CAnonical Time-series CHaracteristics. Data Mining and Knowledge Discovery, 33(6), 1821-1852.\n",
    "\n",
    "\\[2\\] Fulcher, B. D., & Jones, N. S. (2017). hctsa: A computational framework for automated time-series phenotyping using massive feature extraction. Cell systems, 5(5), 527-531.\n",
    "\n",
    "\\[3\\] Fulcher, B. D., Little, M. A., & Jones, N. S. (2013). Highly comparative time-series analysis: the empirical structure of time series and their methods. Journal of the Royal Society Interface, 10(83), 20130048.\n",
    "\n",
    "\\[4\\] Agrahari, R., Nicholson, M., Conran, C., Assem, H. and Kelleher, J.D., 2022. Assessing feature representations for instance-based cross-domain anomaly detection in cloud services univariate time series data. IoT, 3(1), pp.123-144."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
